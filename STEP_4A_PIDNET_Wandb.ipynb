{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngeloBongiorno/AML_2025_project4/blob/vito/STEP_4A_PIDNET_SpikeCharge_Wandb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7QJviwzoN5m"
      },
      "source": [
        "## Install Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHpwU5g8s-Pt"
      },
      "source": [
        "## Upload .zip files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2_aVBiH46K3"
      },
      "source": [
        "For this step you must have the zip files in your Drive into a folder called `AML_project`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xxVbeep6Rlnb",
        "outputId": "2aaceed6-11b9-4554-f61b-b149295c8dd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.7.1)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.14.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/dist-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.2.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.1.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.13.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "!pip install fvcore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2LFD5EkeGs3",
        "outputId": "bc798b33-8094-4ca3-c425-880dba975cee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AML_2025_project4' already exists and is not an empty directory.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "!git clone -b angelo_albumentations --single-branch https://github.com/AngeloBongiorno/AML_2025_project4.git\n",
        "\n",
        "!cp AML_2025_project4/utils.py .\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvdkrFwFI0Qs",
        "outputId": "d59a42d1-2bbc-4198-97bf-3f8ad899fff2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'utils' from '/content/utils.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import importlib\n",
        "import utils  # Replace with the actual module name\n",
        "\n",
        "importlib.reload(utils)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laEb8KOytCpo",
        "outputId": "47309b1f-0838-49a6-8d23-111eb6c79f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping extraction for the dataset, already extracted.\n",
            "{'training_urban': '/content/dataset/Train/Urban', 'training_rural': '/content/dataset/Train/Rural', 'validation_urban': '/content/dataset/Val/Urban', 'validation_rural': '/content/dataset/Val/Rural'}\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "\n",
        "from utils import get_loveDA\n",
        "\n",
        "paths = get_loveDA(verbose=True)\n",
        "print(paths)\n",
        "\n",
        "TRAINING_PATH_URBAN = paths[\"training_urban\"]\n",
        "TRAINING_PATH_RURAL = paths[\"training_rural\"]\n",
        "VAL_PATH_URBAN = paths[\"validation_urban\"]\n",
        "VAL_PATH_RURAL = paths[\"validation_rural\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEM_CLASSES = [\n",
        "    'background',\n",
        "    'building',\n",
        "    'road',\n",
        "    'water',\n",
        "    'barren',\n",
        "    'forest',\n",
        "    'agriculture'\n",
        "]\n",
        "\n",
        "NUM_CLASSES = len(SEM_CLASSES)\n",
        "\n",
        "sem_class_to_idx = {cls: idx for (idx, cls) in enumerate(SEM_CLASSES)}\n",
        "\n",
        "IGNORE_INDEX = -1\n",
        "\n",
        "RESIZE = 512\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "STEP_SIZE = 21\n",
        "\n",
        "GAMMA = 0.5\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "P = 0.5"
      ],
      "metadata": {
        "id": "VJdiPeF5idkI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define and instantiate"
      ],
      "metadata": {
        "id": "dAYUGwGYiFGi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrjECeMs7Sc5"
      },
      "source": [
        "### Define PIDnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QWTXrB6FZo_G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "BatchNorm2d = nn.BatchNorm2d\n",
        "bn_mom = 0.1\n",
        "algc = False\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, no_relu=False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn1 = BatchNorm2d(planes, momentum=bn_mom)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = BatchNorm2d(planes, momentum=bn_mom)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.no_relu = no_relu\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "\n",
        "        if self.no_relu:\n",
        "            return out\n",
        "        else:\n",
        "            return self.relu(out)\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 2\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, no_relu=True):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = BatchNorm2d(planes, momentum=bn_mom)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = BatchNorm2d(planes, momentum=bn_mom)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
        "                               bias=False)\n",
        "        self.bn3 = BatchNorm2d(planes * self.expansion, momentum=bn_mom)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.no_relu = no_relu\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        if self.no_relu:\n",
        "            return out\n",
        "        else:\n",
        "            return self.relu(out)\n",
        "\n",
        "class segmenthead(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, interplanes, outplanes, scale_factor=None):\n",
        "        super(segmenthead, self).__init__()\n",
        "        self.bn1 = BatchNorm2d(inplanes, momentum=bn_mom)\n",
        "        self.conv1 = nn.Conv2d(inplanes, interplanes, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = BatchNorm2d(interplanes, momentum=bn_mom)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(interplanes, outplanes, kernel_size=1, padding=0, bias=True)\n",
        "        self.scale_factor = scale_factor\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(self.relu(self.bn1(x)))\n",
        "        out = self.conv2(self.relu(self.bn2(x)))\n",
        "\n",
        "        if self.scale_factor is not None:\n",
        "            height = x.shape[-2] * self.scale_factor\n",
        "            width = x.shape[-1] * self.scale_factor\n",
        "            out = F.interpolate(out,\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)\n",
        "\n",
        "        return out\n",
        "\n",
        "class DAPPM(nn.Module):\n",
        "    def __init__(self, inplanes, branch_planes, outplanes, BatchNorm=nn.BatchNorm2d):\n",
        "        super(DAPPM, self).__init__()\n",
        "        bn_mom = 0.1\n",
        "        self.scale1 = nn.Sequential(nn.AvgPool2d(kernel_size=5, stride=2, padding=2),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale2 = nn.Sequential(nn.AvgPool2d(kernel_size=9, stride=4, padding=4),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale3 = nn.Sequential(nn.AvgPool2d(kernel_size=17, stride=8, padding=8),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale4 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale0 = nn.Sequential(\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.process1 = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
        "                                    )\n",
        "        self.process2 = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
        "                                    )\n",
        "        self.process3 = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
        "                                    )\n",
        "        self.process4 = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
        "                                    )\n",
        "        self.compression = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes * 5, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes * 5, outplanes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.shortcut = nn.Sequential(\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        width = x.shape[-1]\n",
        "        height = x.shape[-2]\n",
        "        x_list = []\n",
        "\n",
        "        x_list.append(self.scale0(x))\n",
        "        x_list.append(self.process1((F.interpolate(self.scale1(x),\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_list[0])))\n",
        "        x_list.append((self.process2((F.interpolate(self.scale2(x),\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_list[1]))))\n",
        "        x_list.append(self.process3((F.interpolate(self.scale3(x),\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_list[2])))\n",
        "        x_list.append(self.process4((F.interpolate(self.scale4(x),\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_list[3])))\n",
        "\n",
        "        out = self.compression(torch.cat(x_list, 1)) + self.shortcut(x)\n",
        "        return out\n",
        "\n",
        "class PAPPM(nn.Module):\n",
        "    def __init__(self, inplanes, branch_planes, outplanes, BatchNorm=nn.BatchNorm2d):\n",
        "        super(PAPPM, self).__init__()\n",
        "        bn_mom = 0.1\n",
        "        self.scale1 = nn.Sequential(nn.AvgPool2d(kernel_size=5, stride=2, padding=2),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale2 = nn.Sequential(nn.AvgPool2d(kernel_size=9, stride=4, padding=4),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale3 = nn.Sequential(nn.AvgPool2d(kernel_size=17, stride=8, padding=8),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale4 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "        self.scale0 = nn.Sequential(\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "        self.scale_process = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes*4, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes*4, branch_planes*4, kernel_size=3, padding=1, groups=4, bias=False),\n",
        "                                    )\n",
        "\n",
        "\n",
        "        self.compression = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes * 5, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes * 5, outplanes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "        self.shortcut = nn.Sequential(\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        width = x.shape[-1]\n",
        "        height = x.shape[-2]\n",
        "        scale_list = []\n",
        "\n",
        "        x_ = self.scale0(x)\n",
        "        scale_list.append(F.interpolate(self.scale1(x), size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_)\n",
        "        scale_list.append(F.interpolate(self.scale2(x), size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_)\n",
        "        scale_list.append(F.interpolate(self.scale3(x), size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_)\n",
        "        scale_list.append(F.interpolate(self.scale4(x), size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_)\n",
        "\n",
        "        scale_out = self.scale_process(torch.cat(scale_list, 1))\n",
        "\n",
        "        out = self.compression(torch.cat([x_,scale_out], 1)) + self.shortcut(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class PagFM(nn.Module):\n",
        "    def __init__(self, in_channels, mid_channels, after_relu=False, with_channel=False, BatchNorm=nn.BatchNorm2d):\n",
        "        super(PagFM, self).__init__()\n",
        "        self.with_channel = with_channel\n",
        "        self.after_relu = after_relu\n",
        "        self.f_x = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, mid_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(mid_channels)\n",
        "                                )\n",
        "        self.f_y = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, mid_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(mid_channels)\n",
        "                                )\n",
        "        if with_channel:\n",
        "            self.up = nn.Sequential(\n",
        "                                    nn.Conv2d(mid_channels, in_channels,\n",
        "                                              kernel_size=1, bias=False),\n",
        "                                    BatchNorm(in_channels)\n",
        "                                   )\n",
        "        if after_relu:\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        input_size = x.size()\n",
        "        if self.after_relu:\n",
        "            y = self.relu(y)\n",
        "            x = self.relu(x)\n",
        "\n",
        "        y_q = self.f_y(y)\n",
        "        y_q = F.interpolate(y_q, size=[input_size[2], input_size[3]],\n",
        "                            mode='bilinear', align_corners=False)\n",
        "        x_k = self.f_x(x)\n",
        "\n",
        "        if self.with_channel:\n",
        "            sim_map = torch.sigmoid(self.up(x_k * y_q))\n",
        "        else:\n",
        "            sim_map = torch.sigmoid(torch.sum(x_k * y_q, dim=1).unsqueeze(1))\n",
        "\n",
        "        y = F.interpolate(y, size=[input_size[2], input_size[3]],\n",
        "                            mode='bilinear', align_corners=False)\n",
        "        x = (1-sim_map)*x + sim_map*y\n",
        "\n",
        "        return x\n",
        "\n",
        "class Light_Bag(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
        "        super(Light_Bag, self).__init__()\n",
        "        self.conv_p = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(out_channels)\n",
        "                                )\n",
        "        self.conv_i = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(out_channels)\n",
        "                                )\n",
        "\n",
        "    def forward(self, p, i, d):\n",
        "        edge_att = torch.sigmoid(d)\n",
        "\n",
        "        p_add = self.conv_p((1-edge_att)*i + p)\n",
        "        i_add = self.conv_i(i + edge_att*p)\n",
        "\n",
        "        return p_add + i_add\n",
        "\n",
        "\n",
        "class DDFMv2(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
        "        super(DDFMv2, self).__init__()\n",
        "        self.conv_p = nn.Sequential(\n",
        "                                BatchNorm(in_channels),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(out_channels)\n",
        "                                )\n",
        "        self.conv_i = nn.Sequential(\n",
        "                                BatchNorm(in_channels),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(out_channels)\n",
        "                                )\n",
        "\n",
        "    def forward(self, p, i, d):\n",
        "        edge_att = torch.sigmoid(d)\n",
        "\n",
        "        p_add = self.conv_p((1-edge_att)*i + p)\n",
        "        i_add = self.conv_i(i + edge_att*p)\n",
        "\n",
        "        return p_add + i_add\n",
        "\n",
        "class Bag(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
        "        super(Bag, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "                                BatchNorm(in_channels),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=3, padding=1, bias=False)\n",
        "                                )\n",
        "\n",
        "\n",
        "    def forward(self, p, i, d):\n",
        "        edge_att = torch.sigmoid(d)\n",
        "        return self.conv(edge_att*p + (1-edge_att)*i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vjCDANDmZZw3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import logging\n",
        "\n",
        "BatchNorm2d = nn.BatchNorm2d\n",
        "bn_mom = 0.1\n",
        "algc = False\n",
        "\n",
        "\n",
        "\n",
        "class PIDNet(nn.Module):\n",
        "\n",
        "    def __init__(self, m=2, n=3, num_classes=19, planes=64, ppm_planes=96, head_planes=128, augment=True):\n",
        "        super(PIDNet, self).__init__()\n",
        "        self.augment = augment\n",
        "\n",
        "        # I Branch\n",
        "        self.conv1 =  nn.Sequential(\n",
        "                          nn.Conv2d(3,planes,kernel_size=3, stride=2, padding=1),\n",
        "                          BatchNorm2d(planes, momentum=bn_mom),\n",
        "                          nn.ReLU(inplace=True),\n",
        "                          nn.Conv2d(planes,planes,kernel_size=3, stride=2, padding=1),\n",
        "                          BatchNorm2d(planes, momentum=bn_mom),\n",
        "                          nn.ReLU(inplace=True),\n",
        "                      )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(BasicBlock, planes, planes, m)\n",
        "        self.layer2 = self._make_layer(BasicBlock, planes, planes * 2, m, stride=2)\n",
        "        self.layer3 = self._make_layer(BasicBlock, planes * 2, planes * 4, n, stride=2)\n",
        "        self.layer4 = self._make_layer(BasicBlock, planes * 4, planes * 8, n, stride=2)\n",
        "        self.layer5 =  self._make_layer(Bottleneck, planes * 8, planes * 8, 2, stride=2)\n",
        "\n",
        "        # P Branch\n",
        "        self.compression3 = nn.Sequential(\n",
        "                                          nn.Conv2d(planes * 4, planes * 2, kernel_size=1, bias=False),\n",
        "                                          BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                          )\n",
        "\n",
        "        self.compression4 = nn.Sequential(\n",
        "                                          nn.Conv2d(planes * 8, planes * 2, kernel_size=1, bias=False),\n",
        "                                          BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                          )\n",
        "        self.pag3 = PagFM(planes * 2, planes)\n",
        "        self.pag4 = PagFM(planes * 2, planes)\n",
        "\n",
        "        self.layer3_ = self._make_layer(BasicBlock, planes * 2, planes * 2, m)\n",
        "        self.layer4_ = self._make_layer(BasicBlock, planes * 2, planes * 2, m)\n",
        "        self.layer5_ = self._make_layer(Bottleneck, planes * 2, planes * 2, 1)\n",
        "\n",
        "        # D Branch\n",
        "        if m == 2:\n",
        "            self.layer3_d = self._make_single_layer(BasicBlock, planes * 2, planes)\n",
        "            self.layer4_d = self._make_layer(Bottleneck, planes, planes, 1)\n",
        "            self.diff3 = nn.Sequential(\n",
        "                                        nn.Conv2d(planes * 4, planes, kernel_size=3, padding=1, bias=False),\n",
        "                                        BatchNorm2d(planes, momentum=bn_mom),\n",
        "                                        )\n",
        "            self.diff4 = nn.Sequential(\n",
        "                                     nn.Conv2d(planes * 8, planes * 2, kernel_size=3, padding=1, bias=False),\n",
        "                                     BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                     )\n",
        "            self.spp = PAPPM(planes * 16, ppm_planes, planes * 4)\n",
        "            self.dfm = Light_Bag(planes * 4, planes * 4)\n",
        "        else:\n",
        "            self.layer3_d = self._make_single_layer(BasicBlock, planes * 2, planes * 2)\n",
        "            self.layer4_d = self._make_single_layer(BasicBlock, planes * 2, planes * 2)\n",
        "            self.diff3 = nn.Sequential(\n",
        "                                        nn.Conv2d(planes * 4, planes * 2, kernel_size=3, padding=1, bias=False),\n",
        "                                        BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                        )\n",
        "            self.diff4 = nn.Sequential(\n",
        "                                     nn.Conv2d(planes * 8, planes * 2, kernel_size=3, padding=1, bias=False),\n",
        "                                     BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                     )\n",
        "            self.spp = DAPPM(planes * 16, ppm_planes, planes * 4)\n",
        "            self.dfm = Bag(planes * 4, planes * 4)\n",
        "\n",
        "        self.layer5_d = self._make_layer(Bottleneck, planes * 2, planes * 2, 1)\n",
        "\n",
        "        # Prediction Head\n",
        "        if self.augment:\n",
        "            self.seghead_p = segmenthead(planes * 2, head_planes, num_classes)\n",
        "            self.seghead_d = segmenthead(planes * 2, planes, 1)\n",
        "\n",
        "        self.final_layer = segmenthead(planes * 4, head_planes, num_classes)\n",
        "\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion, momentum=bn_mom),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(inplanes, planes, stride, downsample))\n",
        "        inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            if i == (blocks-1):\n",
        "                layers.append(block(inplanes, planes, stride=1, no_relu=True))\n",
        "            else:\n",
        "                layers.append(block(inplanes, planes, stride=1, no_relu=False))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_single_layer(self, block, inplanes, planes, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion, momentum=bn_mom),\n",
        "            )\n",
        "\n",
        "        layer = block(inplanes, planes, stride, downsample, no_relu=True)\n",
        "\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        width_output = x.shape[-1] // 8\n",
        "        height_output = x.shape[-2] // 8\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(self.layer2(self.relu(x)))\n",
        "        x_ = self.layer3_(x)\n",
        "        x_d = self.layer3_d(x)\n",
        "\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x_ = self.pag3(x_, self.compression3(x))\n",
        "        x_d = x_d + F.interpolate(\n",
        "                        self.diff3(x),\n",
        "                        size=[height_output, width_output],\n",
        "                        mode='bilinear', align_corners=algc)\n",
        "        if self.augment:\n",
        "            temp_p = x_\n",
        "\n",
        "        x = self.relu(self.layer4(x))\n",
        "        x_ = self.layer4_(self.relu(x_))\n",
        "        x_d = self.layer4_d(self.relu(x_d))\n",
        "\n",
        "        x_ = self.pag4(x_, self.compression4(x))\n",
        "        x_d = x_d + F.interpolate(\n",
        "                        self.diff4(x),\n",
        "                        size=[height_output, width_output],\n",
        "                        mode='bilinear', align_corners=algc)\n",
        "        if self.augment:\n",
        "            temp_d = x_d\n",
        "\n",
        "        x_ = self.layer5_(self.relu(x_))\n",
        "        x_d = self.layer5_d(self.relu(x_d))\n",
        "        x = F.interpolate(\n",
        "                        self.spp(self.layer5(x)),\n",
        "                        size=[height_output, width_output],\n",
        "                        mode='bilinear', align_corners=algc)\n",
        "\n",
        "        x_ = self.final_layer(self.dfm(x_, x, x_d))\n",
        "\n",
        "        if self.augment:\n",
        "            x_extra_p = self.seghead_p(temp_p)\n",
        "            x_extra_d = self.seghead_d(temp_d)\n",
        "            return [x_extra_p, x_, x_extra_d]\n",
        "        else:\n",
        "            return x_\n",
        "\n",
        "def get_seg_model(cfg, imgnet_pretrained):\n",
        "\n",
        "    if 's' in cfg.MODEL.NAME:\n",
        "        model = PIDNet(m=2, n=3, num_classes=cfg.DATASET.NUM_CLASSES, planes=32, ppm_planes=96, head_planes=128, augment=True)\n",
        "    elif 'm' in cfg.MODEL.NAME:\n",
        "        model = PIDNet(m=2, n=3, num_classes=cfg.DATASET.NUM_CLASSES, planes=64, ppm_planes=96, head_planes=128, augment=True)\n",
        "    else:\n",
        "        model = PIDNet(m=3, n=4, num_classes=cfg.DATASET.NUM_CLASSES, planes=64, ppm_planes=112, head_planes=256, augment=True)\n",
        "\n",
        "    if imgnet_pretrained:\n",
        "        pretrained_state = torch.load(cfg.MODEL.PRETRAINED, map_location='cpu')['state_dict']\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_state = {k: v for k, v in pretrained_state.items() if (k in model_dict and v.shape == model_dict[k].shape)}\n",
        "        model_dict.update(pretrained_state)\n",
        "        msg = 'Loaded {} parameters!'.format(len(pretrained_state))\n",
        "        logging.info('Attention!!!')\n",
        "        logging.info(msg)\n",
        "        logging.info('Over!!!')\n",
        "        model.load_state_dict(model_dict, strict = False)\n",
        "    else:\n",
        "        pretrained_dict = torch.load(cfg.MODEL.PRETRAINED, map_location='cpu')\n",
        "        if 'state_dict' in pretrained_dict:\n",
        "            pretrained_dict = pretrained_dict['state_dict']\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items() if (k[6:] in model_dict and v.shape == model_dict[k[6:]].shape)}\n",
        "        msg = 'Loaded {} parameters!'.format(len(pretrained_dict))\n",
        "        logging.info('Attention!!!')\n",
        "        logging.info(msg)\n",
        "        logging.info('Over!!!')\n",
        "        model_dict.update(pretrained_dict)\n",
        "        model.load_state_dict(model_dict, strict = False)\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_pred_model(name, num_classes):\n",
        "\n",
        "    if 's' in name:\n",
        "        model = PIDNet(m=2, n=3, num_classes=num_classes, planes=32, ppm_planes=96, head_planes=128, augment=False)\n",
        "    elif 'm' in name:\n",
        "        model = PIDNet(m=2, n=3, num_classes=num_classes, planes=64, ppm_planes=96, head_planes=128, augment=False)\n",
        "    else:\n",
        "        model = PIDNet(m=3, n=4, num_classes=num_classes, planes=64, ppm_planes=112, head_planes=256, augment=False)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Discriminator\n",
        "Used for the adversarial approach"
      ],
      "metadata": {
        "id": "3_Wz-64dY5Y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "class FCDiscriminator(nn.Module):\n",
        "\n",
        "\tdef __init__(self, num_classes, ndf = 64):\n",
        "\t\tsuper(FCDiscriminator, self).__init__()\n",
        "\n",
        "\t\tself.conv1 = nn.Conv2d(num_classes, ndf, kernel_size=4, stride=2, padding=1)\n",
        "\t\tself.conv2 = nn.Conv2d(ndf, ndf*2, kernel_size=4, stride=2, padding=1)\n",
        "\t\tself.conv3 = nn.Conv2d(ndf*2, ndf*4, kernel_size=4, stride=2, padding=1)\n",
        "\t\tself.conv4 = nn.Conv2d(ndf*4, ndf*8, kernel_size=4, stride=2, padding=1)\n",
        "\t\tself.classifier = nn.Conv2d(ndf*8, 1, kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "\t\tself.leaky_relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.conv1(x)\n",
        "\t\tx = self.leaky_relu(x)\n",
        "\t\tx = self.conv2(x)\n",
        "\t\tx = self.leaky_relu(x)\n",
        "\t\tx = self.conv3(x)\n",
        "\t\tx = self.leaky_relu(x)\n",
        "\t\tx = self.conv4(x)\n",
        "\t\tx = self.leaky_relu(x)\n",
        "\t\tx = self.classifier(x)\n",
        "\n",
        "\t\treturn x"
      ],
      "metadata": {
        "id": "tCCQZJ9gZAHH"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw9SYUCgi6us"
      },
      "source": [
        "# Dataset & dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset definition"
      ],
      "metadata": {
        "id": "wrMzI_LbjhP_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "T6kSW8hGjAo9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform, target=False, augmentation=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.image_filenames = sorted(os.listdir(image_dir))\n",
        "        self.mask_filenames = sorted(os.listdir(mask_dir))\n",
        "        self.augmentation = augmentation\n",
        "        self.target = target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.mask_filenames[idx])\n",
        "\n",
        "        # Read an image with OpenCV\n",
        "        image = cv2.imread(img_path)\n",
        "        mask = cv2.imread(mask_path)\n",
        "\n",
        "        # By default OpenCV uses BGR color space for color images,\n",
        "        # so we need to convert the image to RGB color space.\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        if self.augmentation:\n",
        "          transformed = self.augmentation(image=image, mask=mask)\n",
        "          image = transformed[\"image\"]\n",
        "          mask = transformed[\"mask\"]\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "\n",
        "\n",
        "        mask_np = np.array(mask)\n",
        "\n",
        "        edge = cv2.Canny(mask_np, 0.1, 0.2)\n",
        "\n",
        "        kernel = np.ones((3, 3), np.uint8)  # Kernel for dilation\n",
        "\n",
        "        edge = edge[6:-6, 6:-6]\n",
        "        edge = np.pad(edge, ((6,6),(6,6)), mode='constant')\n",
        "        boundaries = cv2.dilate(edge, kernel, iterations=1)  # Dilate edges\n",
        "        boundaries = (boundaries > 50) * 1.0 # boundaries matrix is float with 1.0 or 0.0\n",
        "\n",
        "        mask = torch.as_tensor(np.array(mask), dtype=torch.int64) - 1\n",
        "\n",
        "        boundaries_tensor = torch.as_tensor(boundaries, dtype=torch.float32)\n",
        "\n",
        "        # if the dataset is a target dataset, does not return the mask\n",
        "        if self.target == True:\n",
        "          return image, boundaries_tensor\n",
        "        return image, mask, boundaries_tensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations for images & masks\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision.transforms import v2 as T\n",
        "import cv2\n",
        "\n",
        "resize_transform = A.Compose([\n",
        "    A.Resize(height=RESIZE, width=RESIZE, p=1),\n",
        "    A.ToFloat(),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# the best augmentation from previous step is chosen\n",
        "augment = A.HueSaturationValue(\n",
        "    hue_shift_limit=20,\n",
        "    sat_shift_limit=30,\n",
        "    val_shift_limit=20,\n",
        "    p=P)"
      ],
      "metadata": {
        "id": "cOr2yJ_6kvA4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset instantiation"
      ],
      "metadata": {
        "id": "aRC4KXtmj3Pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset objects\n",
        "\n",
        "# TRAINING DATASETS\n",
        "source_dataset = SegmentationDataset(TRAINING_PATH_URBAN + \"/images_png\", TRAINING_PATH_URBAN + \"/masks_png\",\n",
        "                                    transform=resize_transform, augmentation=augment)\n",
        "\n",
        "\n",
        "target_dataset = SegmentationDataset(TRAINING_PATH_RURAL + \"/images_png\", TRAINING_PATH_RURAL + \"/masks_png\",\n",
        "                                    transform=resize_transform, target=True, augmentation=augment)\n",
        "\n",
        "# EVALUATION DATASET\n",
        "\n",
        "val_dataset = SegmentationDataset(VAL_PATH_RURAL + \"/images_png\", VAL_PATH_RURAL + \"/masks_png\",\n",
        "                                    transform=resize_transform)"
      ],
      "metadata": {
        "id": "Zk4ZifehjuyZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loader instantiation"
      ],
      "metadata": {
        "id": "lyTIKtzjj7i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders\n",
        "\n",
        "# TRAINING DATALOADERS\n",
        "source_loader = DataLoader(source_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "target_loader = DataLoader(target_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "\n",
        "# EVALUATION DATALOADERS\n",
        "\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "# enumerate dataloaders\n",
        "source_loader_iter = enumerate(source_loader)\n",
        "target_loader_iter = enumerate(target_loader)\n"
      ],
      "metadata": {
        "id": "vhsQeNzTj_mk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSQUcy7_t2of"
      },
      "source": [
        "# Training Phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4pcqQXrMzza"
      },
      "source": [
        "### Instantiate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hZNWIM0DbnJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "450a00ef-ef0a-4ad2-de6a-b7b0bd93280f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hIBp_8maRr60-B3PF0NVtaA6TYBvO4y-\n",
            "To: /content/PIDNet_S_ImageNet.pth.tar\n",
            "100%|| 38.1M/38.1M [00:00<00:00, 96.8MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imagenet-pretrained pidnet weights downloaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "if (os.path.exists(\"./PIDNet_S_ImageNet.pth.tar\") == False):\n",
        "  url = \"https://drive.google.com/uc?id=1hIBp_8maRr60-B3PF0NVtaA6TYBvO4y-\"\n",
        "  output = \"./\"\n",
        "  gdown.download(url, output, quiet=False)\n",
        "\n",
        "  print(\"imagenet-pretrained pidnet weights downloaded\")\n",
        "\n",
        "\n",
        "class Config:\n",
        "  class MODEL:\n",
        "      NAME = 'pidnet_s'\n",
        "      PRETRAINED = 'PIDNet_S_ImageNet.pth.tar'\n",
        "  class DATASET:\n",
        "      NUM_CLASSES = NUM_CLASSES\n",
        "\n",
        "cfg = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define loss functions"
      ],
      "metadata": {
        "id": "p_wwWFwFkIoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Extra Semantic Loss (Classica CrossEntropy Loss)\n",
        "class CrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, num_outputs, weight=None, balance_weights=[0.4, 1.0], sb_weights=1.0):\n",
        "        super(CrossEntropyLoss, self).__init__()\n",
        "        self.loss = nn.CrossEntropyLoss(weight=weight, ignore_index=IGNORE_INDEX)\n",
        "        self.num_outputs = num_outputs\n",
        "        self.balance_weights = balance_weights\n",
        "        self.sb_weights = sb_weights\n",
        "\n",
        "    def _forward(self, pred, target):\n",
        "        return self.loss(pred, target)\n",
        "\n",
        "    def forward(self, score, target):\n",
        "\n",
        "        if self.num_outputs == 1:\n",
        "            score = [score]\n",
        "\n",
        "        if len(self.balance_weights) == len(score):\n",
        "            return sum([w * self._forward(x, target) for (w, x) in zip(self.balance_weights, score)])\n",
        "        elif len(score) == 1:\n",
        "            return self.sb_weights * self._forward(score[0], target)\n",
        "        else:\n",
        "            raise ValueError(\"lengths of prediction and target are not identical!\")\n",
        "\n",
        "\n",
        "# Weighted Binary Cross Entropy per i bordi\n",
        "def weighted_bce(bd_pre, target):\n",
        "    n, c, h, w = bd_pre.size()\n",
        "    log_p = bd_pre.permute(0,2,3,1).contiguous().view(1, -1)\n",
        "    target_t = target.view(1, -1)\n",
        "\n",
        "    pos_index = (target_t == 1)\n",
        "    neg_index = (target_t == 0)\n",
        "\n",
        "    weight = torch.zeros_like(log_p)\n",
        "    pos_num = pos_index.sum()\n",
        "    neg_num = neg_index.sum()\n",
        "    sum_num = pos_num + neg_num\n",
        "    weight[pos_index] = neg_num * 1.0 / sum_num\n",
        "    weight[neg_index] = pos_num * 1.0 / sum_num\n",
        "\n",
        "    loss = F.binary_cross_entropy_with_logits(log_p, target_t, weight, reduction='mean')\n",
        "\n",
        "    return loss\n",
        "\n",
        "class BondaryLoss(nn.Module):\n",
        "    def __init__(self, coeff_bce = 20.0):\n",
        "        super(BondaryLoss, self).__init__()\n",
        "        self.coeff_bce = coeff_bce\n",
        "\n",
        "    def forward(self, bd_pre, bd_gt):\n",
        "\n",
        "        bce_loss = self.coeff_bce * weighted_bce(bd_pre, bd_gt)\n",
        "        loss = bce_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "# PIDNet Loss Totale\n",
        "class PIDNetLoss(nn.Module):\n",
        "    def __init__(self, lambda_0=0.4, lambda_1=20, lambda_2=1, lambda_3=1, threshold=0.8):\n",
        "        super(PIDNetLoss, self).__init__()\n",
        "        self.sem_loss = CrossEntropyLoss(num_outputs=2, balance_weights=[lambda_0, lambda_2], sb_weights=lambda_3)\n",
        "        self.bd_loss = BondaryLoss(coeff_bce=lambda_1)\n",
        "\n",
        "        self.threshold = threshold\n",
        "\n",
        "\n",
        "    def forward(self, pred_p, pred_main, target, boundary_head, boundary_mask):\n",
        "        \"\"\"\n",
        "        pred_p: output branch P (B, C, H, W)\n",
        "        pred_main: output principale (B, C, H, W)\n",
        "        target: ground truth segmentazione (B, H, W)\n",
        "        boundary_head: predizione dei bordi (B, 1, H, W)\n",
        "        boundary_mask: ground truth dei bordi (B, 1, H, W)\n",
        "        \"\"\"\n",
        "\n",
        "        loss_s = self.sem_loss([pred_p, pred_main], target) # l_0 e l_2\n",
        "        loss_b = self.bd_loss(boundary_head, boundary_mask.unsqueeze(1)) # l_1\n",
        "\n",
        "        # l_3\n",
        "        filler = torch.ones_like(target) * IGNORE_INDEX\n",
        "        bd_label = torch.where(F.sigmoid(boundary_head[:,0,:,:])>self.threshold, target, filler)\n",
        "        loss_sb = self.sem_loss([pred_main], bd_label)\n",
        "\n",
        "\n",
        "        loss = loss_s + loss_b + loss_sb\n",
        "\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "7uJvTyhWp2Ky"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upscaling function"
      ],
      "metadata": {
        "id": "tTTJR3Ly3T_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def Upscaling(outputs, boundary_mask, model):\n",
        "    \"\"\"Upscale trough bilinear interpolation -> riporto le dimensioni dell'output a quelli originali\n",
        "    Quindi passiamo da 64 x 64 della rete a 512 x 512\"\"\"\n",
        "\n",
        "    h, w = boundary_mask.size(1), boundary_mask.size(2)\n",
        "    ph, pw = outputs[0].size(2), outputs[0].size(3)\n",
        "    if ph != h or pw != w:\n",
        "        for i in range(len(outputs)):\n",
        "            outputs[i] = F.interpolate(outputs[i], size=(h, w), mode='bilinear', align_corners=True)\n",
        "    if model.augment:\n",
        "        pred_p, pred_main, boundary_head = outputs  # P, I, D branches\n",
        "    else:\n",
        "        pred_p = None\n",
        "        pred_main = outputs\n",
        "        boundary_head = None  # Nessuna branch D se augment=False\n",
        "\n",
        "    return pred_p, pred_main, boundary_head"
      ],
      "metadata": {
        "id": "6A2YoQKT3Tu8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train with WanDB"
      ],
      "metadata": {
        "id": "jOCaZndAkPy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab: installazione wandb\n",
        "!pip install -q wandb\n",
        "\n",
        "# Login W&B (inserisci manualmente il tuo API Key quando richiesto)\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Dej2qus6MoEl",
        "outputId": "9ef970e9-dd25-4f4a-fba5-c201187718c9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvitosilver1999\u001b[0m (\u001b[33mvitosilver1999-politecnico-di-torino\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchmetrics.segmentation import MeanIoU\n",
        "from itertools import cycle\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.optim.lr_scheduler import LambdaLR, SequentialLR, StepLR\n",
        "\n",
        "# Set seeds\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "wzOSAh9KMpDw"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(config=None):\n",
        "    with wandb.init(config=config):\n",
        "        config = wandb.config\n",
        "\n",
        "        model = get_seg_model(cfg, imgnet_pretrained=True)\n",
        "        model_D = FCDiscriminator(num_classes=NUM_CLASSES)\n",
        "        bce_loss = torch.nn.BCEWithLogitsLoss()\n",
        "        loss_fn = PIDNetLoss(threshold=0.8)\n",
        "\n",
        "        model.to(device)\n",
        "        model_D.to(device)\n",
        "\n",
        "        optimizer = torch.optim.SGD(model.parameters(), lr=config.LR)\n",
        "        optimizer_D = torch.optim.Adam(model_D.parameters(), lr=config.LR_D)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=GAMMA, patience=3, threshold=0.01)\n",
        "\n",
        "        miou_classes = MeanIoU(num_classes=7, input_format=\"index\", per_class=True).to(device)\n",
        "\n",
        "        charge = 0\n",
        "        source_label = 0\n",
        "        target_label = 1\n",
        "        num_classes=7\n",
        "\n",
        "        for epoch in range(EPOCHS):\n",
        "            loss_seg_source_raw_value = 0\n",
        "            loss_adv_target_raw_value = 0\n",
        "            loss_D_raw_value = 0\n",
        "            total_train_samples = 0\n",
        "\n",
        "            loss_D_valid_updates = 0\n",
        "            total_train_samples_D = 0\n",
        "\n",
        "            model.train()\n",
        "            model_D.train()\n",
        "\n",
        "            train_loader =  zip(source_loader, target_loader)\n",
        "            num_batches = min(len(source_loader), len(target_loader))\n",
        "\n",
        "            pbar = tqdm(enumerate(train_loader), total=num_batches, desc=f\"Epoch {epoch+1} [Training]\")\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            optimizer_D.zero_grad()\n",
        "\n",
        "            for i, (source_batch, target_batch) in pbar:\n",
        "                # --- Train G with Source ---\n",
        "                for param in model_D.parameters():\n",
        "                    param.requires_grad = False\n",
        "\n",
        "                X, y, boundary_mask = source_batch\n",
        "                X, y, boundary_mask = X.to(device), y.to(device), boundary_mask.to(device)\n",
        "\n",
        "                outputs = model(X)\n",
        "                pred_p, pred_main, boundary_head = Upscaling(outputs=outputs, boundary_mask=boundary_mask, model=model)\n",
        "\n",
        "                loss_seg_source_raw = loss_fn(pred_p, pred_main, y, boundary_head, boundary_mask)\n",
        "                (loss_seg_source_raw * config.LAMBDA_SEG).backward()\n",
        "                loss_seg_source_raw_value += loss_seg_source_raw.item()\n",
        "\n",
        "                # --- Train G with Target ---\n",
        "                X_target, boundary_mask_target = target_batch\n",
        "                X_target, boundary_mask_target = X_target.to(device), boundary_mask_target.to(device)\n",
        "\n",
        "                outputs_target = model(X_target)\n",
        "                pred_p_target, pred_main_target, boundary_head_target = Upscaling(outputs=outputs_target, boundary_mask=boundary_mask_target, model=model)\n",
        "\n",
        "                D_out = model_D(F.softmax(pred_main_target, dim=1))\n",
        "                loss_adv_target_raw = bce_loss(D_out, torch.full_like(D_out, source_label))\n",
        "                (loss_adv_target_raw * config.LAMBDA_ADV_TARGET).backward()\n",
        "                loss_adv_target_raw_value += loss_adv_target_raw.item()\n",
        "\n",
        "                # --- Train D with Spike-and-Charge ---\n",
        "                for param in model_D.parameters():\n",
        "                        param.requires_grad = True\n",
        "\n",
        "                D_out_source = model_D(F.softmax(pred_main.detach(), dim=1))\n",
        "                loss_D_source = bce_loss(D_out_source, torch.full_like(D_out_source, source_label))\n",
        "\n",
        "                D_out_target = model_D(F.softmax(pred_main_target.detach(), dim=1))\n",
        "                loss_D_target = bce_loss(D_out_target, torch.full_like(D_out_target, target_label))\n",
        "\n",
        "                loss_D_total = loss_D_source + loss_D_target\n",
        "\n",
        "                if loss_D_total.item() > config.disc_loss_spike_threshold:\n",
        "                    charge += 1\n",
        "                else:\n",
        "                    charge = max(charge - 1, 0)\n",
        "\n",
        "                if charge >= config.charge_threshold:\n",
        "                    loss_D_total.backward()\n",
        "                    optimizer_D.step()\n",
        "                    loss_D_raw_value += loss_D_total.item()\n",
        "                    loss_D_valid_updates += 1\n",
        "                    charge = 0  # discharge\n",
        "                    total_train_samples_D += X.size(0)\n",
        "\n",
        "                optimizer.step()\n",
        "\n",
        "                total_train_samples += X.size(0)\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    \"Loss_seg_raw\": f\"{loss_seg_source_raw_value / (i+1):.4f}\",\n",
        "                    \"Loss_adv_raw\": f\"{loss_adv_target_raw_value / (i+1):.4f}\",\n",
        "                    \"Loss_D_raw\": f\"{loss_D_raw_value / loss_D_valid_updates:.4f}\" if loss_D_valid_updates > 0 else \"N/A\",\n",
        "                    \"Charge\": charge\n",
        "                })\n",
        "\n",
        "            # ---------------------- VALIDATION ----------------------\n",
        "\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            miou_classes.reset()\n",
        "            total_val_samples = 0\n",
        "\n",
        "            with torch.inference_mode():\n",
        "                pbar_val = tqdm(enumerate(val_loader), total=len(val_loader), desc=f\"Epoch {epoch+1} [Validation]\")\n",
        "\n",
        "                for batch, (X_val, y_val, boundary_mask) in pbar_val:\n",
        "                    X_val, y_val, boundary_mask = X_val.to(device), y_val.to(device), boundary_mask.to(device)\n",
        "\n",
        "                    outputs = model(X_val)\n",
        "                    pred_p, pred_main, boundary_head = Upscaling(outputs=outputs, boundary_mask=boundary_mask, model=model)\n",
        "\n",
        "                    loss = loss_fn(pred_p, pred_main, y_val, boundary_head, boundary_mask)\n",
        "                    val_loss += loss.item()\n",
        "                    total_val_samples += X_val.size(0)\n",
        "\n",
        "                    preds = pred_main.argmax(dim=1)\n",
        "                    valid_mask = (y_val >= 0) & (y_val < num_classes)\n",
        "                    preds_flat = preds[valid_mask]\n",
        "                    targets_flat = y_val[valid_mask]\n",
        "\n",
        "                    miou_classes.update(preds_flat, targets_flat)\n",
        "\n",
        "                    pbar_val.set_postfix({\n",
        "                        \"Val_Loss\": f\"{val_loss / (batch+1):.4f}\",\n",
        "                        \"mIoU\": f\"{miou_classes.compute().mean():.4f}\"\n",
        "                    })\n",
        "\n",
        "            avg_val_loss = val_loss / total_val_samples\n",
        "            miou_per_class = miou_classes.compute()\n",
        "            miou = miou_per_class.mean()\n",
        "\n",
        "            print(f\"\\n Validation Loss: {avg_val_loss:.4f}\")\n",
        "            print(f\" Overall mIoU: {miou_per_class.mean():.4f}\")\n",
        "            for i, iou in enumerate(miou_per_class):\n",
        "                class_name = list(sem_class_to_idx.keys())[list(sem_class_to_idx.values()).index(i)]\n",
        "                print(f\"   {class_name} IoU: {iou:.4f}\")\n",
        "\n",
        "            wandb.log({\n",
        "                \"mIoU\": miou,\n",
        "                \"loss_seg_source_raw\": loss_seg_source_raw_value / total_train_samples,\n",
        "                \"loss_adv_target_raw\": loss_adv_target_raw_value / total_train_samples,\n",
        "                \"loss_D_raw\": loss_D_raw_value / total_train_samples_D\n",
        "            })\n",
        "\n",
        "            scheduler.step(miou)\n",
        "            print(scheduler.get_last_lr())\n"
      ],
      "metadata": {
        "id": "QbpQQmWiMsY2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'bayes',\n",
        "    'metric': {'name': 'mIoU', 'goal': 'maximize'},\n",
        "    'parameters': {\n",
        "        'LR': {'min': 0.00001, 'max': 0.001},\n",
        "        'LR_D': {'min': 0.000001, 'max': 0.00001},\n",
        "        'LAMBDA_ADV_TARGET': {'min': 0.001, 'max': 0.02},\n",
        "        'LAMBDA_SEG': {'min': 0.1, 'max': 1.0},\n",
        "        'charge_threshold': {'values': [5]},\n",
        "        'disc_loss_spike_threshold': {'min': 0.1, 'max': 1.0},\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"Advance Machine Learning\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqGzxkc1SEoN",
        "outputId": "8c4e04b9-f627-4901-b95a-77c6ef81692b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: c7b99ij1\n",
            "Sweep URL: https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/sweeps/c7b99ij1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, function=train, count=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nMdK4jwkTRLI",
        "outputId": "a89d695a-bae5-466d-a78b-72c078a29c72"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bsdf1zn3 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tLAMBDA_ADV_TARGET: 0.006060635074800489\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tLAMBDA_SEG: 0.5207557163562558\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tLR: 0.0007469779213785554\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tLR_D: 3.4102198581835493e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcharge_threshold: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdisc_loss_spike_threshold: 0.3717200026053088\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250509_184012-bsdf1zn3</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/runs/bsdf1zn3' target=\"_blank\">clean-sweep-1</a></strong> to <a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/sweeps/c7b99ij1' target=\"_blank\">https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/sweeps/c7b99ij1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning' target=\"_blank\">https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/sweeps/c7b99ij1' target=\"_blank\">https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/sweeps/c7b99ij1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/runs/bsdf1zn3' target=\"_blank\">https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/runs/bsdf1zn3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Training]: 100%|| 73/73 [00:36<00:00,  1.99it/s, Loss_seg_raw=9.8007, Loss_adv_raw=0.6866, Loss_D_raw=1.3864, Charge=3]\n",
            "Epoch 1 [Validation]: 100%|| 62/62 [00:15<00:00,  4.13it/s, Val_Loss=9.9687, mIoU=0.1046]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.6230\n",
            " Overall mIoU: 0.1046\n",
            "   background IoU: 0.2945\n",
            "   building IoU: 0.1483\n",
            "   road IoU: 0.0619\n",
            "   water IoU: 0.1191\n",
            "   barren IoU: 0.0379\n",
            "   forest IoU: 0.0703\n",
            "   agriculture IoU: 0.0000\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 2 [Training]: 100%|| 73/73 [00:35<00:00,  2.06it/s, Loss_seg_raw=5.5473, Loss_adv_raw=0.6916, Loss_D_raw=1.3860, Charge=1]\n",
            "Epoch 2 [Validation]: 100%|| 62/62 [00:14<00:00,  4.14it/s, Val_Loss=7.7024, mIoU=0.1464]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4814\n",
            " Overall mIoU: 0.1464\n",
            "   background IoU: 0.4080\n",
            "   building IoU: 0.1638\n",
            "   road IoU: 0.0969\n",
            "   water IoU: 0.3205\n",
            "   barren IoU: 0.0145\n",
            "   forest IoU: 0.0192\n",
            "   agriculture IoU: 0.0021\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 3 [Training]: 100%|| 73/73 [00:35<00:00,  2.05it/s, Loss_seg_raw=4.8684, Loss_adv_raw=0.6931, Loss_D_raw=1.3857, Charge=4]\n",
            "Epoch 3 [Validation]: 100%|| 62/62 [00:14<00:00,  4.15it/s, Val_Loss=6.3165, mIoU=0.1776]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.3948\n",
            " Overall mIoU: 0.1776\n",
            "   background IoU: 0.4379\n",
            "   building IoU: 0.2536\n",
            "   road IoU: 0.1591\n",
            "   water IoU: 0.2673\n",
            "   barren IoU: 0.0418\n",
            "   forest IoU: 0.0817\n",
            "   agriculture IoU: 0.0017\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 4 [Training]: 100%|| 73/73 [00:35<00:00,  2.04it/s, Loss_seg_raw=4.7695, Loss_adv_raw=0.6926, Loss_D_raw=1.3845, Charge=2]\n",
            "Epoch 4 [Validation]: 100%|| 62/62 [00:14<00:00,  4.19it/s, Val_Loss=6.5026, mIoU=0.1590]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4064\n",
            " Overall mIoU: 0.1590\n",
            "   background IoU: 0.4352\n",
            "   building IoU: 0.1660\n",
            "   road IoU: 0.1426\n",
            "   water IoU: 0.3025\n",
            "   barren IoU: 0.0195\n",
            "   forest IoU: 0.0256\n",
            "   agriculture IoU: 0.0216\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 5 [Training]: 100%|| 73/73 [00:35<00:00,  2.05it/s, Loss_seg_raw=4.6010, Loss_adv_raw=0.6923, Loss_D_raw=1.3838, Charge=0]\n",
            "Epoch 5 [Validation]: 100%|| 62/62 [00:14<00:00,  4.20it/s, Val_Loss=7.0700, mIoU=0.1663]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4419\n",
            " Overall mIoU: 0.1663\n",
            "   background IoU: 0.4528\n",
            "   building IoU: 0.2312\n",
            "   road IoU: 0.1131\n",
            "   water IoU: 0.3109\n",
            "   barren IoU: 0.0185\n",
            "   forest IoU: 0.0294\n",
            "   agriculture IoU: 0.0077\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 6 [Training]: 100%|| 73/73 [00:35<00:00,  2.05it/s, Loss_seg_raw=4.5693, Loss_adv_raw=0.6916, Loss_D_raw=1.3826, Charge=3]\n",
            "Epoch 6 [Validation]: 100%|| 62/62 [00:14<00:00,  4.18it/s, Val_Loss=5.8597, mIoU=0.1938]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.3662\n",
            " Overall mIoU: 0.1938\n",
            "   background IoU: 0.4719\n",
            "   building IoU: 0.2277\n",
            "   road IoU: 0.1708\n",
            "   water IoU: 0.2901\n",
            "   barren IoU: 0.0834\n",
            "   forest IoU: 0.0531\n",
            "   agriculture IoU: 0.0596\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 7 [Training]: 100%|| 73/73 [00:35<00:00,  2.03it/s, Loss_seg_raw=4.4239, Loss_adv_raw=0.6941, Loss_D_raw=1.3816, Charge=1]\n",
            "Epoch 7 [Validation]: 100%|| 62/62 [00:15<00:00,  4.12it/s, Val_Loss=6.7534, mIoU=0.1859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4221\n",
            " Overall mIoU: 0.1859\n",
            "   background IoU: 0.4710\n",
            "   building IoU: 0.1992\n",
            "   road IoU: 0.1824\n",
            "   water IoU: 0.3542\n",
            "   barren IoU: 0.0064\n",
            "   forest IoU: 0.0222\n",
            "   agriculture IoU: 0.0660\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 8 [Training]: 100%|| 73/73 [00:35<00:00,  2.04it/s, Loss_seg_raw=4.3068, Loss_adv_raw=0.6874, Loss_D_raw=1.3816, Charge=4]\n",
            "Epoch 8 [Validation]: 100%|| 62/62 [00:14<00:00,  4.19it/s, Val_Loss=6.1809, mIoU=0.1939]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.3863\n",
            " Overall mIoU: 0.1939\n",
            "   background IoU: 0.4677\n",
            "   building IoU: 0.1535\n",
            "   road IoU: 0.1896\n",
            "   water IoU: 0.3203\n",
            "   barren IoU: 0.0940\n",
            "   forest IoU: 0.0600\n",
            "   agriculture IoU: 0.0721\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 9 [Training]: 100%|| 73/73 [00:35<00:00,  2.05it/s, Loss_seg_raw=4.2020, Loss_adv_raw=0.6962, Loss_D_raw=1.3777, Charge=2]\n",
            "Epoch 9 [Validation]: 100%|| 62/62 [00:14<00:00,  4.13it/s, Val_Loss=6.2833, mIoU=0.1996]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.3927\n",
            " Overall mIoU: 0.1996\n",
            "   background IoU: 0.4732\n",
            "   building IoU: 0.2382\n",
            "   road IoU: 0.2042\n",
            "   water IoU: 0.3355\n",
            "   barren IoU: 0.0369\n",
            "   forest IoU: 0.0371\n",
            "   agriculture IoU: 0.0720\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 10 [Training]: 100%|| 73/73 [00:35<00:00,  2.06it/s, Loss_seg_raw=4.1503, Loss_adv_raw=0.7098, Loss_D_raw=1.3738, Charge=0]\n",
            "Epoch 10 [Validation]: 100%|| 62/62 [00:14<00:00,  4.18it/s, Val_Loss=6.5642, mIoU=0.1947]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4103\n",
            " Overall mIoU: 0.1947\n",
            "   background IoU: 0.4738\n",
            "   building IoU: 0.1555\n",
            "   road IoU: 0.1863\n",
            "   water IoU: 0.3687\n",
            "   barren IoU: 0.0694\n",
            "   forest IoU: 0.0477\n",
            "   agriculture IoU: 0.0611\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 11 [Training]: 100%|| 73/73 [00:35<00:00,  2.05it/s, Loss_seg_raw=4.0663, Loss_adv_raw=0.6968, Loss_D_raw=1.3665, Charge=3]\n",
            "Epoch 11 [Validation]: 100%|| 62/62 [00:15<00:00,  4.12it/s, Val_Loss=6.5581, mIoU=0.1860]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4099\n",
            " Overall mIoU: 0.1860\n",
            "   background IoU: 0.4766\n",
            "   building IoU: 0.1983\n",
            "   road IoU: 0.1714\n",
            "   water IoU: 0.3064\n",
            "   barren IoU: 0.0394\n",
            "   forest IoU: 0.0260\n",
            "   agriculture IoU: 0.0842\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 12 [Training]: 100%|| 73/73 [00:35<00:00,  2.04it/s, Loss_seg_raw=3.9942, Loss_adv_raw=0.7136, Loss_D_raw=1.3657, Charge=1]\n",
            "Epoch 12 [Validation]: 100%|| 62/62 [00:14<00:00,  4.16it/s, Val_Loss=6.0009, mIoU=0.2083]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.3751\n",
            " Overall mIoU: 0.2083\n",
            "   background IoU: 0.4444\n",
            "   building IoU: 0.2205\n",
            "   road IoU: 0.1884\n",
            "   water IoU: 0.4204\n",
            "   barren IoU: 0.0415\n",
            "   forest IoU: 0.0645\n",
            "   agriculture IoU: 0.0782\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 13 [Training]: 100%|| 73/73 [00:35<00:00,  2.05it/s, Loss_seg_raw=3.9630, Loss_adv_raw=0.7229, Loss_D_raw=1.3639, Charge=4]\n",
            "Epoch 13 [Validation]: 100%|| 62/62 [00:14<00:00,  4.19it/s, Val_Loss=6.4201, mIoU=0.1954]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4013\n",
            " Overall mIoU: 0.1954\n",
            "   background IoU: 0.4813\n",
            "   building IoU: 0.2066\n",
            "   road IoU: 0.1842\n",
            "   water IoU: 0.3191\n",
            "   barren IoU: 0.0304\n",
            "   forest IoU: 0.0306\n",
            "   agriculture IoU: 0.1154\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 14 [Training]: 100%|| 73/73 [00:35<00:00,  2.05it/s, Loss_seg_raw=3.9566, Loss_adv_raw=0.6812, Loss_D_raw=1.3575, Charge=2]\n",
            "Epoch 14 [Validation]: 100%|| 62/62 [00:14<00:00,  4.17it/s, Val_Loss=6.8307, mIoU=0.1746]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4269\n",
            " Overall mIoU: 0.1746\n",
            "   background IoU: 0.4015\n",
            "   building IoU: 0.1581\n",
            "   road IoU: 0.1466\n",
            "   water IoU: 0.3777\n",
            "   barren IoU: 0.0477\n",
            "   forest IoU: 0.0636\n",
            "   agriculture IoU: 0.0273\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 15 [Training]: 100%|| 73/73 [00:35<00:00,  2.05it/s, Loss_seg_raw=3.9386, Loss_adv_raw=0.7695, Loss_D_raw=1.3562, Charge=0]\n",
            "Epoch 15 [Validation]: 100%|| 62/62 [00:14<00:00,  4.16it/s, Val_Loss=6.3376, mIoU=0.2146]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.3961\n",
            " Overall mIoU: 0.2146\n",
            "   background IoU: 0.4729\n",
            "   building IoU: 0.2331\n",
            "   road IoU: 0.1981\n",
            "   water IoU: 0.3588\n",
            "   barren IoU: 0.0543\n",
            "   forest IoU: 0.0236\n",
            "   agriculture IoU: 0.1616\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 16 [Training]: 100%|| 73/73 [00:35<00:00,  2.04it/s, Loss_seg_raw=3.9205, Loss_adv_raw=0.6844, Loss_D_raw=1.3546, Charge=3]\n",
            "Epoch 16 [Validation]: 100%|| 62/62 [00:14<00:00,  4.14it/s, Val_Loss=7.2753, mIoU=0.1833]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4547\n",
            " Overall mIoU: 0.1833\n",
            "   background IoU: 0.4441\n",
            "   building IoU: 0.1572\n",
            "   road IoU: 0.1496\n",
            "   water IoU: 0.4310\n",
            "   barren IoU: 0.0420\n",
            "   forest IoU: 0.0353\n",
            "   agriculture IoU: 0.0240\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 17 [Training]: 100%|| 73/73 [00:35<00:00,  2.04it/s, Loss_seg_raw=3.8890, Loss_adv_raw=0.6870, Loss_D_raw=1.3593, Charge=1]\n",
            "Epoch 17 [Validation]: 100%|| 62/62 [00:14<00:00,  4.17it/s, Val_Loss=6.5656, mIoU=0.2030]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4104\n",
            " Overall mIoU: 0.2030\n",
            "   background IoU: 0.4453\n",
            "   building IoU: 0.1835\n",
            "   road IoU: 0.1960\n",
            "   water IoU: 0.3480\n",
            "   barren IoU: 0.0557\n",
            "   forest IoU: 0.0312\n",
            "   agriculture IoU: 0.1616\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 18 [Training]: 100%|| 73/73 [00:35<00:00,  2.04it/s, Loss_seg_raw=3.8398, Loss_adv_raw=0.7889, Loss_D_raw=1.3563, Charge=4]\n",
            "Epoch 18 [Validation]: 100%|| 62/62 [00:14<00:00,  4.18it/s, Val_Loss=6.5097, mIoU=0.2071]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4069\n",
            " Overall mIoU: 0.2071\n",
            "   background IoU: 0.4767\n",
            "   building IoU: 0.2251\n",
            "   road IoU: 0.1790\n",
            "   water IoU: 0.4009\n",
            "   barren IoU: 0.0617\n",
            "   forest IoU: 0.0556\n",
            "   agriculture IoU: 0.0505\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 19 [Training]: 100%|| 73/73 [00:35<00:00,  2.04it/s, Loss_seg_raw=3.7844, Loss_adv_raw=0.7047, Loss_D_raw=1.3435, Charge=2]\n",
            "Epoch 19 [Validation]: 100%|| 62/62 [00:14<00:00,  4.15it/s, Val_Loss=6.3896, mIoU=0.2305]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.3993\n",
            " Overall mIoU: 0.2305\n",
            "   background IoU: 0.4915\n",
            "   building IoU: 0.1847\n",
            "   road IoU: 0.1869\n",
            "   water IoU: 0.4266\n",
            "   barren IoU: 0.0810\n",
            "   forest IoU: 0.0357\n",
            "   agriculture IoU: 0.2071\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 20 [Training]: 100%|| 73/73 [00:35<00:00,  2.05it/s, Loss_seg_raw=3.7667, Loss_adv_raw=0.6895, Loss_D_raw=1.3509, Charge=0]\n",
            "Epoch 20 [Validation]: 100%|| 62/62 [00:14<00:00,  4.17it/s, Val_Loss=6.7468, mIoU=0.2055]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4217\n",
            " Overall mIoU: 0.2055\n",
            "   background IoU: 0.4843\n",
            "   building IoU: 0.1711\n",
            "   road IoU: 0.1910\n",
            "   water IoU: 0.4138\n",
            "   barren IoU: 0.0572\n",
            "   forest IoU: 0.0733\n",
            "   agriculture IoU: 0.0480\n",
            "[0.0007469779213785554]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss_D_raw</td><td></td></tr><tr><td>loss_adv_target_raw</td><td></td></tr><tr><td>loss_seg_source_raw</td><td></td></tr><tr><td>mIoU</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss_D_raw</td><td>0.08887</td></tr><tr><td>loss_adv_target_raw</td><td>0.04354</td></tr><tr><td>loss_seg_source_raw</td><td>0.23786</td></tr><tr><td>mIoU</td><td>0.20553</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">clean-sweep-1</strong> at: <a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/runs/bsdf1zn3' target=\"_blank\">https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/runs/bsdf1zn3</a><br> View project at: <a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning' target=\"_blank\">https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250509_184012-bsdf1zn3/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m9n5eyej with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tLAMBDA_ADV_TARGET: 0.01183183723265431\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tLAMBDA_SEG: 0.9149162202291944\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tLR: 0.0009142839742179252\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tLR_D: 8.123114845049537e-06\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcharge_threshold: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdisc_loss_spike_threshold: 0.4283191028490606\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250509_185719-m9n5eyej</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/runs/m9n5eyej' target=\"_blank\">sage-sweep-2</a></strong> to <a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/sweeps/c7b99ij1' target=\"_blank\">https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/sweeps/c7b99ij1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning' target=\"_blank\">https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/sweeps/c7b99ij1' target=\"_blank\">https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/sweeps/c7b99ij1</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/runs/m9n5eyej' target=\"_blank\">https://wandb.ai/vitosilver1999-politecnico-di-torino/Advance%20Machine%20Learning/runs/m9n5eyej</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1 [Training]: 100%|| 73/73 [00:35<00:00,  2.04it/s, Loss_seg_raw=9.1636, Loss_adv_raw=0.6906, Loss_D_raw=1.3863, Charge=3]\n",
            "Epoch 1 [Validation]: 100%|| 62/62 [00:15<00:00,  4.11it/s, Val_Loss=21.3217, mIoU=0.0520]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 1.3326\n",
            " Overall mIoU: 0.0520\n",
            "   background IoU: 0.2080\n",
            "   building IoU: 0.0669\n",
            "   road IoU: 0.0306\n",
            "   water IoU: 0.0547\n",
            "   barren IoU: 0.0028\n",
            "   forest IoU: 0.0012\n",
            "   agriculture IoU: 0.0000\n",
            "[0.0009142839742179252]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 2 [Training]: 100%|| 73/73 [00:35<00:00,  2.05it/s, Loss_seg_raw=7.5381, Loss_adv_raw=0.6931, Loss_D_raw=1.3864, Charge=1]\n",
            "Epoch 2 [Validation]: 100%|| 62/62 [00:14<00:00,  4.16it/s, Val_Loss=18.6211, mIoU=0.0784]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 1.1638\n",
            " Overall mIoU: 0.0784\n",
            "   background IoU: 0.3836\n",
            "   building IoU: 0.0327\n",
            "   road IoU: 0.0093\n",
            "   water IoU: 0.0680\n",
            "   barren IoU: 0.0279\n",
            "   forest IoU: 0.0273\n",
            "   agriculture IoU: 0.0000\n",
            "[0.0009142839742179252]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 3 [Training]: 100%|| 73/73 [00:35<00:00,  2.05it/s, Loss_seg_raw=5.9573, Loss_adv_raw=0.6928, Loss_D_raw=1.3865, Charge=4]\n",
            "Epoch 3 [Validation]: 100%|| 62/62 [00:15<00:00,  4.10it/s, Val_Loss=6.1912, mIoU=0.0707]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.3870\n",
            " Overall mIoU: 0.0707\n",
            "   background IoU: 0.4266\n",
            "   building IoU: 0.0601\n",
            "   road IoU: 0.0016\n",
            "   water IoU: 0.0068\n",
            "   barren IoU: 0.0000\n",
            "   forest IoU: 0.0000\n",
            "   agriculture IoU: 0.0000\n",
            "[0.0009142839742179252]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 4 [Training]: 100%|| 73/73 [00:35<00:00,  2.04it/s, Loss_seg_raw=6.0947, Loss_adv_raw=0.6828, Loss_D_raw=1.3857, Charge=2]\n",
            "Epoch 4 [Validation]: 100%|| 62/62 [00:15<00:00,  4.13it/s, Val_Loss=25.5185, mIoU=0.0741]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 1.5949\n",
            " Overall mIoU: 0.0741\n",
            "   background IoU: 0.4164\n",
            "   building IoU: 0.0851\n",
            "   road IoU: 0.0042\n",
            "   water IoU: 0.0000\n",
            "   barren IoU: 0.0041\n",
            "   forest IoU: 0.0093\n",
            "   agriculture IoU: 0.0000\n",
            "[0.0009142839742179252]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 5 [Training]: 100%|| 73/73 [00:35<00:00,  2.04it/s, Loss_seg_raw=5.5783, Loss_adv_raw=0.6961, Loss_D_raw=1.3846, Charge=0]\n",
            "Epoch 5 [Validation]: 100%|| 62/62 [00:14<00:00,  4.19it/s, Val_Loss=6.9983, mIoU=0.0794]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4374\n",
            " Overall mIoU: 0.0794\n",
            "   background IoU: 0.3966\n",
            "   building IoU: 0.1501\n",
            "   road IoU: 0.0000\n",
            "   water IoU: 0.0062\n",
            "   barren IoU: 0.0018\n",
            "   forest IoU: 0.0008\n",
            "   agriculture IoU: 0.0000\n",
            "[0.0009142839742179252]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 6 [Training]: 100%|| 73/73 [00:35<00:00,  2.06it/s, Loss_seg_raw=5.2221, Loss_adv_raw=0.6821, Loss_D_raw=1.3832, Charge=3]\n",
            "Epoch 6 [Validation]: 100%|| 62/62 [00:14<00:00,  4.16it/s, Val_Loss=9.5491, mIoU=0.0817]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.5968\n",
            " Overall mIoU: 0.0817\n",
            "   background IoU: 0.4082\n",
            "   building IoU: 0.1423\n",
            "   road IoU: 0.0058\n",
            "   water IoU: 0.0016\n",
            "   barren IoU: 0.0081\n",
            "   forest IoU: 0.0056\n",
            "   agriculture IoU: 0.0000\n",
            "[0.0009142839742179252]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 7 [Training]: 100%|| 73/73 [00:35<00:00,  2.05it/s, Loss_seg_raw=4.9432, Loss_adv_raw=0.6974, Loss_D_raw=1.3807, Charge=1]\n",
            "Epoch 7 [Validation]: 100%|| 62/62 [00:14<00:00,  4.15it/s, Val_Loss=7.5358, mIoU=0.0544]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4710\n",
            " Overall mIoU: 0.0544\n",
            "   background IoU: 0.2731\n",
            "   building IoU: 0.0941\n",
            "   road IoU: 0.0101\n",
            "   water IoU: 0.0001\n",
            "   barren IoU: 0.0000\n",
            "   forest IoU: 0.0031\n",
            "   agriculture IoU: 0.0000\n",
            "[0.0009142839742179252]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 8 [Training]: 100%|| 73/73 [00:35<00:00,  2.05it/s, Loss_seg_raw=5.0758, Loss_adv_raw=0.7026, Loss_D_raw=1.3790, Charge=4]\n",
            "Epoch 8 [Validation]: 100%|| 62/62 [00:14<00:00,  4.16it/s, Val_Loss=6.7863, mIoU=0.0760]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Validation Loss: 0.4241\n",
            " Overall mIoU: 0.0760\n",
            "   background IoU: 0.3723\n",
            "   building IoU: 0.1316\n",
            "   road IoU: 0.0168\n",
            "   water IoU: 0.0071\n",
            "   barren IoU: 0.0000\n",
            "   forest IoU: 0.0039\n",
            "   agriculture IoU: 0.0000\n",
            "[0.0009142839742179252]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 9 [Training]:  33%|      | 24/73 [00:12<00:22,  2.18it/s, Loss_seg_raw=5.0949, Loss_adv_raw=0.5731, Loss_D_raw=1.4028, Charge=3]\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "UrjECeMs7Sc5",
        "aRC4KXtmj3Pi",
        "p_wwWFwFkIoR",
        "tTTJR3Ly3T_F"
      ],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
