{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngeloBongiorno/AML_2025_project4/blob/angelo/STEP_5_CUT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7QJviwzoN5m"
      },
      "source": [
        "## Install Dependency & DeepLab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHpwU5g8s-Pt"
      },
      "source": [
        "## Upload .zip files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2_aVBiH46K3"
      },
      "source": [
        "For this step you must have the zip files in your Drive into a folder called `AML_project`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xxVbeep6Rlnb",
        "outputId": "4ddde2b5-eff3-4847-ad69-0f56649f6957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->torchmetrics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.7.1\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (3.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.2.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.13.2)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=cbecb0e1259a215f974a826e2d0da547eb4fa65187e8e0b7c0939d2f351d1eaf\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/71/95/3b8fde5c65c6e4a806e0867c1651dcc71a1cb2f3430e8f355f\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=95a239df3bbe5361c5b7fe9b018ff2386567ccd72acf195aaaa2444e4be6aca6\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/5e/16/6117f8fe7e9c0c161a795e10d94645ebcf301ccbd01f66d8ec\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.1.1 yacs-0.1.8\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "!pip install fvcore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2LFD5EkeGs3",
        "outputId": "076774f8-5ff1-487f-9556-7e67311a14be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AML_2025_project4'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 211 (delta 56), reused 40 (delta 40), pack-reused 139 (from 2)\u001b[K\n",
            "Receiving objects: 100% (211/211), 94.53 MiB | 13.99 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "!git  clone -b vito --single-branch https://github.com/AngeloBongiorno/AML_2025_project4.git\n",
        "\n",
        "!cp AML_2025_project4/utils.py .\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvdkrFwFI0Qs",
        "outputId": "15535e6f-186c-4f9e-e0f5-57994d0e018e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'utils' from '/content/utils.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import importlib\n",
        "import utils\n",
        "\n",
        "importlib.reload(utils)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laEb8KOytCpo",
        "outputId": "fb4ae914-5c30-453b-eaeb-3f45544ff30f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting training...\n",
            "training extracted!\n",
            "Extracting validation...\n",
            "validation extracted!\n",
            "Extracting training_cut...\n",
            "training_cut extracted!\n",
            "Extraction check completed!\n",
            "{'training_urban': '/content/dataset/Train/Urban', 'training_rural': '/content/dataset/Train/Rural', 'validation_urban': '/content/dataset/Val/Urban', 'validation_rural': '/content/dataset/Val/Rural', 'training_urban_cut': '/content/dataset/Train_CUT/Urban'}\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "\n",
        "from utils import get_loveDA\n",
        "\n",
        "# loads the CUT version of the urban training set\n",
        "paths = get_loveDA(verbose=True, train_cut=True)\n",
        "print(paths)\n",
        "\n",
        "TRAINING_PATH_URBAN = paths[\"training_urban\"]\n",
        "TRAINING_PATH_RURAL = paths[\"training_rural\"]\n",
        "TRAINING_PATH_URBAN_CUT = paths[\"training_urban_cut\"]\n",
        "VAL_PATH_URBAN = paths[\"validation_urban\"]\n",
        "VAL_PATH_RURAL = paths[\"validation_rural\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEM_CLASSES = [\n",
        "    'background',\n",
        "    'building',\n",
        "    'road',\n",
        "    'water',\n",
        "    'barren',\n",
        "    'forest',\n",
        "    'agriculture'\n",
        "]\n",
        "\n",
        "NUM_CLASSES = len(SEM_CLASSES)\n",
        "sem_class_to_idx = {cls: idx for (idx, cls) in enumerate(SEM_CLASSES)}\n",
        "\n",
        "RESIZE = (512, 512)\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "EPOCHS = 20\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "STEP_SIZE = 14\n",
        "\n",
        "GAMMA = 0.1\n",
        "\n",
        "LR = 1e-2\n",
        "\n",
        "LOSS_TYPE = \"ohem\"\n",
        "\n",
        "IGNORE_INDEX = -1\n",
        "\n",
        "WEIGHT_DECAY = 1e-3\n",
        "\n",
        "MOMENTUM = 0.8\n",
        "\n",
        "PLATEAU = True\n",
        "\n",
        "SHOW_IMG = False"
      ],
      "metadata": {
        "id": "VJdiPeF5idkI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define and instantiate"
      ],
      "metadata": {
        "id": "dAYUGwGYiFGi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrjECeMs7Sc5"
      },
      "source": [
        "### Define PIDnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QWTXrB6FZo_G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "BatchNorm2d = nn.BatchNorm2d\n",
        "bn_mom = 0.1\n",
        "algc = False\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, no_relu=False):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn1 = BatchNorm2d(planes, momentum=bn_mom)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = BatchNorm2d(planes, momentum=bn_mom)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.no_relu = no_relu\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "\n",
        "        if self.no_relu:\n",
        "            return out\n",
        "        else:\n",
        "            return self.relu(out)\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 2\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, no_relu=True):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = BatchNorm2d(planes, momentum=bn_mom)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = BatchNorm2d(planes, momentum=bn_mom)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1,\n",
        "                               bias=False)\n",
        "        self.bn3 = BatchNorm2d(planes * self.expansion, momentum=bn_mom)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.no_relu = no_relu\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        if self.no_relu:\n",
        "            return out\n",
        "        else:\n",
        "            return self.relu(out)\n",
        "\n",
        "class segmenthead(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, interplanes, outplanes, scale_factor=None):\n",
        "        super(segmenthead, self).__init__()\n",
        "        self.bn1 = BatchNorm2d(inplanes, momentum=bn_mom)\n",
        "        self.conv1 = nn.Conv2d(inplanes, interplanes, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = BatchNorm2d(interplanes, momentum=bn_mom)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(interplanes, outplanes, kernel_size=1, padding=0, bias=True)\n",
        "        self.scale_factor = scale_factor\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(self.relu(self.bn1(x)))\n",
        "        out = self.conv2(self.relu(self.bn2(x)))\n",
        "\n",
        "        if self.scale_factor is not None:\n",
        "            height = x.shape[-2] * self.scale_factor\n",
        "            width = x.shape[-1] * self.scale_factor\n",
        "            out = F.interpolate(out,\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)\n",
        "\n",
        "        return out\n",
        "\n",
        "class DAPPM(nn.Module):\n",
        "    def __init__(self, inplanes, branch_planes, outplanes, BatchNorm=nn.BatchNorm2d):\n",
        "        super(DAPPM, self).__init__()\n",
        "        bn_mom = 0.1\n",
        "        self.scale1 = nn.Sequential(nn.AvgPool2d(kernel_size=5, stride=2, padding=2),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale2 = nn.Sequential(nn.AvgPool2d(kernel_size=9, stride=4, padding=4),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale3 = nn.Sequential(nn.AvgPool2d(kernel_size=17, stride=8, padding=8),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale4 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale0 = nn.Sequential(\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.process1 = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
        "                                    )\n",
        "        self.process2 = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
        "                                    )\n",
        "        self.process3 = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
        "                                    )\n",
        "        self.process4 = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes, branch_planes, kernel_size=3, padding=1, bias=False),\n",
        "                                    )\n",
        "        self.compression = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes * 5, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes * 5, outplanes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.shortcut = nn.Sequential(\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        width = x.shape[-1]\n",
        "        height = x.shape[-2]\n",
        "        x_list = []\n",
        "\n",
        "        x_list.append(self.scale0(x))\n",
        "        x_list.append(self.process1((F.interpolate(self.scale1(x),\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_list[0])))\n",
        "        x_list.append((self.process2((F.interpolate(self.scale2(x),\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_list[1]))))\n",
        "        x_list.append(self.process3((F.interpolate(self.scale3(x),\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_list[2])))\n",
        "        x_list.append(self.process4((F.interpolate(self.scale4(x),\n",
        "                        size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_list[3])))\n",
        "\n",
        "        out = self.compression(torch.cat(x_list, 1)) + self.shortcut(x)\n",
        "        return out\n",
        "\n",
        "class PAPPM(nn.Module):\n",
        "    def __init__(self, inplanes, branch_planes, outplanes, BatchNorm=nn.BatchNorm2d):\n",
        "        super(PAPPM, self).__init__()\n",
        "        bn_mom = 0.1\n",
        "        self.scale1 = nn.Sequential(nn.AvgPool2d(kernel_size=5, stride=2, padding=2),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale2 = nn.Sequential(nn.AvgPool2d(kernel_size=9, stride=4, padding=4),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale3 = nn.Sequential(nn.AvgPool2d(kernel_size=17, stride=8, padding=8),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "        self.scale4 = nn.Sequential(nn.AdaptiveAvgPool2d((1, 1)),\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "        self.scale0 = nn.Sequential(\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, branch_planes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "        self.scale_process = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes*4, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes*4, branch_planes*4, kernel_size=3, padding=1, groups=4, bias=False),\n",
        "                                    )\n",
        "\n",
        "\n",
        "        self.compression = nn.Sequential(\n",
        "                                    BatchNorm(branch_planes * 5, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(branch_planes * 5, outplanes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "        self.shortcut = nn.Sequential(\n",
        "                                    BatchNorm(inplanes, momentum=bn_mom),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(inplanes, outplanes, kernel_size=1, bias=False),\n",
        "                                    )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        width = x.shape[-1]\n",
        "        height = x.shape[-2]\n",
        "        scale_list = []\n",
        "\n",
        "        x_ = self.scale0(x)\n",
        "        scale_list.append(F.interpolate(self.scale1(x), size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_)\n",
        "        scale_list.append(F.interpolate(self.scale2(x), size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_)\n",
        "        scale_list.append(F.interpolate(self.scale3(x), size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_)\n",
        "        scale_list.append(F.interpolate(self.scale4(x), size=[height, width],\n",
        "                        mode='bilinear', align_corners=algc)+x_)\n",
        "\n",
        "        scale_out = self.scale_process(torch.cat(scale_list, 1))\n",
        "\n",
        "        out = self.compression(torch.cat([x_,scale_out], 1)) + self.shortcut(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class PagFM(nn.Module):\n",
        "    def __init__(self, in_channels, mid_channels, after_relu=False, with_channel=False, BatchNorm=nn.BatchNorm2d):\n",
        "        super(PagFM, self).__init__()\n",
        "        self.with_channel = with_channel\n",
        "        self.after_relu = after_relu\n",
        "        self.f_x = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, mid_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(mid_channels)\n",
        "                                )\n",
        "        self.f_y = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, mid_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(mid_channels)\n",
        "                                )\n",
        "        if with_channel:\n",
        "            self.up = nn.Sequential(\n",
        "                                    nn.Conv2d(mid_channels, in_channels,\n",
        "                                              kernel_size=1, bias=False),\n",
        "                                    BatchNorm(in_channels)\n",
        "                                   )\n",
        "        if after_relu:\n",
        "            self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        input_size = x.size()\n",
        "        if self.after_relu:\n",
        "            y = self.relu(y)\n",
        "            x = self.relu(x)\n",
        "\n",
        "        y_q = self.f_y(y)\n",
        "        y_q = F.interpolate(y_q, size=[input_size[2], input_size[3]],\n",
        "                            mode='bilinear', align_corners=False)\n",
        "        x_k = self.f_x(x)\n",
        "\n",
        "        if self.with_channel:\n",
        "            sim_map = torch.sigmoid(self.up(x_k * y_q))\n",
        "        else:\n",
        "            sim_map = torch.sigmoid(torch.sum(x_k * y_q, dim=1).unsqueeze(1))\n",
        "\n",
        "        y = F.interpolate(y, size=[input_size[2], input_size[3]],\n",
        "                            mode='bilinear', align_corners=False)\n",
        "        x = (1-sim_map)*x + sim_map*y\n",
        "\n",
        "        return x\n",
        "\n",
        "class Light_Bag(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
        "        super(Light_Bag, self).__init__()\n",
        "        self.conv_p = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(out_channels)\n",
        "                                )\n",
        "        self.conv_i = nn.Sequential(\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(out_channels)\n",
        "                                )\n",
        "\n",
        "    def forward(self, p, i, d):\n",
        "        edge_att = torch.sigmoid(d)\n",
        "\n",
        "        p_add = self.conv_p((1-edge_att)*i + p)\n",
        "        i_add = self.conv_i(i + edge_att*p)\n",
        "\n",
        "        return p_add + i_add\n",
        "\n",
        "\n",
        "class DDFMv2(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
        "        super(DDFMv2, self).__init__()\n",
        "        self.conv_p = nn.Sequential(\n",
        "                                BatchNorm(in_channels),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(out_channels)\n",
        "                                )\n",
        "        self.conv_i = nn.Sequential(\n",
        "                                BatchNorm(in_channels),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=1, bias=False),\n",
        "                                BatchNorm(out_channels)\n",
        "                                )\n",
        "\n",
        "    def forward(self, p, i, d):\n",
        "        edge_att = torch.sigmoid(d)\n",
        "\n",
        "        p_add = self.conv_p((1-edge_att)*i + p)\n",
        "        i_add = self.conv_i(i + edge_att*p)\n",
        "\n",
        "        return p_add + i_add\n",
        "\n",
        "class Bag(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, BatchNorm=nn.BatchNorm2d):\n",
        "        super(Bag, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "                                BatchNorm(in_channels),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Conv2d(in_channels, out_channels,\n",
        "                                          kernel_size=3, padding=1, bias=False)\n",
        "                                )\n",
        "\n",
        "\n",
        "    def forward(self, p, i, d):\n",
        "        edge_att = torch.sigmoid(d)\n",
        "        return self.conv(edge_att*p + (1-edge_att)*i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vjCDANDmZZw3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import logging\n",
        "\n",
        "BatchNorm2d = nn.BatchNorm2d\n",
        "bn_mom = 0.1\n",
        "algc = False\n",
        "\n",
        "\n",
        "\n",
        "class PIDNet(nn.Module):\n",
        "\n",
        "    def __init__(self, m=2, n=3, num_classes=19, planes=64, ppm_planes=96, head_planes=128, augment=True):\n",
        "        super(PIDNet, self).__init__()\n",
        "        self.augment = augment\n",
        "\n",
        "        # I Branch\n",
        "        self.conv1 =  nn.Sequential(\n",
        "                          nn.Conv2d(3,planes,kernel_size=3, stride=2, padding=1),\n",
        "                          BatchNorm2d(planes, momentum=bn_mom),\n",
        "                          nn.ReLU(inplace=True),\n",
        "                          nn.Conv2d(planes,planes,kernel_size=3, stride=2, padding=1),\n",
        "                          BatchNorm2d(planes, momentum=bn_mom),\n",
        "                          nn.ReLU(inplace=True),\n",
        "                      )\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self._make_layer(BasicBlock, planes, planes, m)\n",
        "        self.layer2 = self._make_layer(BasicBlock, planes, planes * 2, m, stride=2)\n",
        "        self.layer3 = self._make_layer(BasicBlock, planes * 2, planes * 4, n, stride=2)\n",
        "        self.layer4 = self._make_layer(BasicBlock, planes * 4, planes * 8, n, stride=2)\n",
        "        self.layer5 =  self._make_layer(Bottleneck, planes * 8, planes * 8, 2, stride=2)\n",
        "\n",
        "        # P Branch\n",
        "        self.compression3 = nn.Sequential(\n",
        "                                          nn.Conv2d(planes * 4, planes * 2, kernel_size=1, bias=False),\n",
        "                                          BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                          )\n",
        "\n",
        "        self.compression4 = nn.Sequential(\n",
        "                                          nn.Conv2d(planes * 8, planes * 2, kernel_size=1, bias=False),\n",
        "                                          BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                          )\n",
        "        self.pag3 = PagFM(planes * 2, planes)\n",
        "        self.pag4 = PagFM(planes * 2, planes)\n",
        "\n",
        "        self.layer3_ = self._make_layer(BasicBlock, planes * 2, planes * 2, m)\n",
        "        self.layer4_ = self._make_layer(BasicBlock, planes * 2, planes * 2, m)\n",
        "        self.layer5_ = self._make_layer(Bottleneck, planes * 2, planes * 2, 1)\n",
        "\n",
        "        # D Branch\n",
        "        if m == 2:\n",
        "            self.layer3_d = self._make_single_layer(BasicBlock, planes * 2, planes)\n",
        "            self.layer4_d = self._make_layer(Bottleneck, planes, planes, 1)\n",
        "            self.diff3 = nn.Sequential(\n",
        "                                        nn.Conv2d(planes * 4, planes, kernel_size=3, padding=1, bias=False),\n",
        "                                        BatchNorm2d(planes, momentum=bn_mom),\n",
        "                                        )\n",
        "            self.diff4 = nn.Sequential(\n",
        "                                     nn.Conv2d(planes * 8, planes * 2, kernel_size=3, padding=1, bias=False),\n",
        "                                     BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                     )\n",
        "            self.spp = PAPPM(planes * 16, ppm_planes, planes * 4)\n",
        "            self.dfm = Light_Bag(planes * 4, planes * 4)\n",
        "        else:\n",
        "            self.layer3_d = self._make_single_layer(BasicBlock, planes * 2, planes * 2)\n",
        "            self.layer4_d = self._make_single_layer(BasicBlock, planes * 2, planes * 2)\n",
        "            self.diff3 = nn.Sequential(\n",
        "                                        nn.Conv2d(planes * 4, planes * 2, kernel_size=3, padding=1, bias=False),\n",
        "                                        BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                        )\n",
        "            self.diff4 = nn.Sequential(\n",
        "                                     nn.Conv2d(planes * 8, planes * 2, kernel_size=3, padding=1, bias=False),\n",
        "                                     BatchNorm2d(planes * 2, momentum=bn_mom),\n",
        "                                     )\n",
        "            self.spp = DAPPM(planes * 16, ppm_planes, planes * 4)\n",
        "            self.dfm = Bag(planes * 4, planes * 4)\n",
        "\n",
        "        self.layer5_d = self._make_layer(Bottleneck, planes * 2, planes * 2, 1)\n",
        "\n",
        "        # Prediction Head\n",
        "        if self.augment:\n",
        "            self.seghead_p = segmenthead(planes * 2, head_planes, num_classes)\n",
        "            self.seghead_d = segmenthead(planes * 2, planes, 1)\n",
        "\n",
        "        self.final_layer = segmenthead(planes * 4, head_planes, num_classes)\n",
        "\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "    def _make_layer(self, block, inplanes, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion, momentum=bn_mom),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(inplanes, planes, stride, downsample))\n",
        "        inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            if i == (blocks-1):\n",
        "                layers.append(block(inplanes, planes, stride=1, no_relu=True))\n",
        "            else:\n",
        "                layers.append(block(inplanes, planes, stride=1, no_relu=False))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _make_single_layer(self, block, inplanes, planes, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion, momentum=bn_mom),\n",
        "            )\n",
        "\n",
        "        layer = block(inplanes, planes, stride, downsample, no_relu=True)\n",
        "\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        width_output = x.shape[-1] // 8\n",
        "        height_output = x.shape[-2] // 8\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.relu(self.layer2(self.relu(x)))\n",
        "        x_ = self.layer3_(x)\n",
        "        x_d = self.layer3_d(x)\n",
        "\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x_ = self.pag3(x_, self.compression3(x))\n",
        "        x_d = x_d + F.interpolate(\n",
        "                        self.diff3(x),\n",
        "                        size=[height_output, width_output],\n",
        "                        mode='bilinear', align_corners=algc)\n",
        "        if self.augment:\n",
        "            temp_p = x_\n",
        "\n",
        "        x = self.relu(self.layer4(x))\n",
        "        x_ = self.layer4_(self.relu(x_))\n",
        "        x_d = self.layer4_d(self.relu(x_d))\n",
        "\n",
        "        x_ = self.pag4(x_, self.compression4(x))\n",
        "        x_d = x_d + F.interpolate(\n",
        "                        self.diff4(x),\n",
        "                        size=[height_output, width_output],\n",
        "                        mode='bilinear', align_corners=algc)\n",
        "        if self.augment:\n",
        "            temp_d = x_d\n",
        "\n",
        "        x_ = self.layer5_(self.relu(x_))\n",
        "        x_d = self.layer5_d(self.relu(x_d))\n",
        "        x = F.interpolate(\n",
        "                        self.spp(self.layer5(x)),\n",
        "                        size=[height_output, width_output],\n",
        "                        mode='bilinear', align_corners=algc)\n",
        "\n",
        "        x_ = self.final_layer(self.dfm(x_, x, x_d))\n",
        "\n",
        "        if self.augment:\n",
        "            x_extra_p = self.seghead_p(temp_p)\n",
        "            x_extra_d = self.seghead_d(temp_d)\n",
        "            return [x_extra_p, x_, x_extra_d]\n",
        "        else:\n",
        "            return x_\n",
        "\n",
        "def get_seg_model(cfg, imgnet_pretrained):\n",
        "\n",
        "    if 's' in cfg.MODEL.NAME:\n",
        "        model = PIDNet(m=2, n=3, num_classes=cfg.DATASET.NUM_CLASSES, planes=32, ppm_planes=96, head_planes=128, augment=True)\n",
        "    elif 'm' in cfg.MODEL.NAME:\n",
        "        model = PIDNet(m=2, n=3, num_classes=cfg.DATASET.NUM_CLASSES, planes=64, ppm_planes=96, head_planes=128, augment=True)\n",
        "    else:\n",
        "        model = PIDNet(m=3, n=4, num_classes=cfg.DATASET.NUM_CLASSES, planes=64, ppm_planes=112, head_planes=256, augment=True)\n",
        "\n",
        "    if imgnet_pretrained:\n",
        "        pretrained_state = torch.load(cfg.MODEL.PRETRAINED, map_location='cpu')['state_dict']\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_state = {k: v for k, v in pretrained_state.items() if (k in model_dict and v.shape == model_dict[k].shape)}\n",
        "        model_dict.update(pretrained_state)\n",
        "        msg = 'Loaded {} parameters!'.format(len(pretrained_state))\n",
        "        logging.info('Attention!!!')\n",
        "        logging.info(msg)\n",
        "        logging.info('Over!!!')\n",
        "        model.load_state_dict(model_dict, strict = False)\n",
        "    else:\n",
        "        pretrained_dict = torch.load(cfg.MODEL.PRETRAINED, map_location='cpu')\n",
        "        if 'state_dict' in pretrained_dict:\n",
        "            pretrained_dict = pretrained_dict['state_dict']\n",
        "        model_dict = model.state_dict()\n",
        "        pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items() if (k[6:] in model_dict and v.shape == model_dict[k[6:]].shape)}\n",
        "        msg = 'Loaded {} parameters!'.format(len(pretrained_dict))\n",
        "        logging.info('Attention!!!')\n",
        "        logging.info(msg)\n",
        "        logging.info('Over!!!')\n",
        "        model_dict.update(pretrained_dict)\n",
        "        model.load_state_dict(model_dict, strict = False)\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_pred_model(name, num_classes):\n",
        "\n",
        "    if 's' in name:\n",
        "        model = PIDNet(m=2, n=3, num_classes=num_classes, planes=32, ppm_planes=96, head_planes=128, augment=False)\n",
        "    elif 'm' in name:\n",
        "        model = PIDNet(m=2, n=3, num_classes=num_classes, planes=64, ppm_planes=96, head_planes=128, augment=False)\n",
        "    else:\n",
        "        model = PIDNet(m=3, n=4, num_classes=num_classes, planes=64, ppm_planes=112, head_planes=256, augment=False)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4pcqQXrMzza"
      },
      "source": [
        "### Instantiate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZNWIM0DbnJv",
        "outputId": "eff93ec3-9222-48ec-a320-3c1e4e4ba8a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1hIBp_8maRr60-B3PF0NVtaA6TYBvO4y-\n",
            "To: /content/PIDNet_S_ImageNet.pth.tar\n",
            "100%|██████████| 38.1M/38.1M [00:00<00:00, 50.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imagenet-pretrained pidnet weights downloaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "if (os.path.exists(\"./PIDNet_S_ImageNet.pth.tar\") == False):\n",
        "  url = \"https://drive.google.com/uc?id=1hIBp_8maRr60-B3PF0NVtaA6TYBvO4y-\"\n",
        "  output = \"./\"\n",
        "  gdown.download(url, output, quiet=False)\n",
        "\n",
        "  print(\"imagenet-pretrained pidnet weights downloaded\")\n",
        "\n",
        "\n",
        "class Config:\n",
        "  class MODEL:\n",
        "      NAME = 'pidnet_s'\n",
        "      PRETRAINED = 'PIDNet_S_ImageNet.pth.tar'\n",
        "  class DATASET:\n",
        "      NUM_CLASSES = NUM_CLASSES\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "model = get_seg_model(cfg, imgnet_pretrained=True)\n",
        "next(model.parameters()).device\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw9SYUCgi6us"
      },
      "source": [
        "# Dataset & dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset definition"
      ],
      "metadata": {
        "id": "wrMzI_LbjhP_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "T6kSW8hGjAo9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None, target_transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        #self.boundary_transform = boundary_transform\n",
        "        self.image_filenames = sorted(os.listdir(image_dir))\n",
        "        self.mask_filenames = sorted(os.listdir(mask_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.mask_filenames[idx])\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")  # Assicura che sia RGB\n",
        "        mask = Image.open(mask_path).convert(\"L\")  # Converti la maschera in scala di grigi (1 canale)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.target_transform:\n",
        "          mask = self.target_transform(mask)\n",
        "\n",
        "        mask_np = np.array(mask)\n",
        "\n",
        "        #mask_grayscale = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        edge = cv2.Canny(mask_np, 0.1, 0.2)\n",
        "\n",
        "        kernel = np.ones((3, 3), np.uint8)  # Kernel for dilation\n",
        "\n",
        "        edge = edge[6:-6, 6:-6]\n",
        "        edge = np.pad(edge, ((6,6),(6,6)), mode='constant')\n",
        "        boundaries = cv2.dilate(edge, kernel, iterations=1)  # Dilate edges\n",
        "        boundaries = (boundaries > 50) * 1.0 # boundaries matrix is float with 1.0 or 0.0\n",
        "\n",
        "        #if self.target_transform:\n",
        "        #  boundaries = self.boundary_transform(boundaries)\n",
        "\n",
        "        mask = torch.as_tensor(np.array(mask), dtype=torch.int64) - 1\n",
        "\n",
        "        boundaries_tensor = torch.as_tensor(boundaries, dtype=torch.float32)\n",
        "\n",
        "        return image, mask, boundaries_tensor  # Return (image, mask) pair"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset instantiation"
      ],
      "metadata": {
        "id": "aRC4KXtmj3Pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataset objects\n",
        "val_ratio = 0.2\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "\n",
        "# Define transformations for images & masks\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize(RESIZE, interpolation=Image.BILINEAR),\n",
        "    transforms.ToTensor(),  # Convert image to tensor\n",
        "])\n",
        "\n",
        "\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.Resize(RESIZE, interpolation=Image.NEAREST),\n",
        "])\n",
        "\n",
        "\n",
        "train_and_val_dataset_urban = SegmentationDataset(\n",
        "    TRAINING_PATH_URBAN + \"/images_png\",\n",
        "    TRAINING_PATH_URBAN + \"/masks_png\",\n",
        "    transform=image_transform,\n",
        "    target_transform = mask_transform\n",
        ")\n",
        "\n",
        "train_and_val_dataset_urban_cut = SegmentationDataset(\n",
        "    TRAINING_PATH_URBAN_CUT + \"/images_png\",\n",
        "    TRAINING_PATH_URBAN_CUT + \"/masks_png\",\n",
        "    transform=image_transform,\n",
        "    target_transform = mask_transform\n",
        ")\n",
        "\n",
        "val_size = int(len(train_and_val_dataset_urban) * val_ratio)\n",
        "train_size = len(train_and_val_dataset_urban) - val_size\n",
        "\n",
        "#---------------------- VALIDATION DATASET ----------------------\n",
        "_, val_dataset = random_split(train_and_val_dataset_urban, [train_size, val_size], generator=generator)\n",
        "print(f\"Validation size: {len(val_dataset)}\")\n",
        "\n",
        "#---------------------- TRAIN DATASET----------------------\n",
        "# the training set has augmented images through CUT\n",
        "train_dataset, _ = random_split(train_and_val_dataset_urban_cut, [train_size, val_size], generator=generator)\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "\n",
        "#---------------------- TEST DATASET----------------------\n",
        "test_dataset = SegmentationDataset(VAL_PATH_RURAL + \"/images_png\", VAL_PATH_RURAL + \"/masks_png\",\n",
        "                                    transform=image_transform, target_transform = mask_transform,)\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "id": "9YvrOh5Fj2QY",
        "outputId": "26202949-6a86-4ea4-ff5c-3af75ecf6f19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation size: 231\n",
            "Train dataset size: 925\n",
            "Test dataset size: 992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loader instantiation"
      ],
      "metadata": {
        "id": "lyTIKtzjj7i0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "vhsQeNzTj_mk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9iwZbSR9jMrt"
      },
      "outputs": [],
      "source": [
        "from utils import show\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "if SHOW_IMG:\n",
        "  print(next(iter(train_loader))[0].shape, next(iter(train_loader))[1].shape, next(iter(train_loader))[2].shape)\n",
        "\n",
        "  batch = next(iter(train_loader))  # (images, masks, boundaries)\n",
        "  images, masks, boundaries = batch  # Unpack the batch\n",
        "\n",
        "  fig, axes = plt.subplots(3, 3, figsize=(10, 10))  # 3 images, each with RGB, mask, and boundary\n",
        "\n",
        "  for i in range(3):  # Show first 3 images\n",
        "      axes[i, 0].imshow(images[i].permute(1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
        "      axes[i, 0].set_title(\"Image\")\n",
        "\n",
        "      axes[i, 1].imshow(masks[i].cpu().numpy(), cmap=\"gray\")  # Show mask\n",
        "      axes[i, 1].set_title(\"Mask\")\n",
        "\n",
        "      axes[i, 2].imshow(boundaries[i].cpu().numpy(), cmap=\"gray\")  # Show boundaries\n",
        "      axes[i, 2].set_title(\"Boundaries\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSQUcy7_t2of"
      },
      "source": [
        "# Training Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAbmz5Cz4I4H",
        "outputId": "fd28900d-1b05-467d-aa47-65d48e0fdda9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "if PLATEAU:\n",
        "  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=GAMMA, patience=3, threshold=0.01)\n",
        "else:\n",
        "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "\n",
        "print(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OScLa7UOTLSc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Extra Semantic Loss (Classica CrossEntropy Loss)\n",
        "class CrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, num_outputs, weight=None, balance_weights=[0.4, 1.0], sb_weights=1.0):\n",
        "        super(CrossEntropyLoss, self).__init__()\n",
        "        self.loss = nn.CrossEntropyLoss(weight=weight, ignore_index=IGNORE_INDEX)\n",
        "        self.num_outputs = num_outputs\n",
        "        self.balance_weights = balance_weights\n",
        "        self.sb_weights = sb_weights\n",
        "\n",
        "    def _forward(self, pred, target):\n",
        "        return self.loss(pred, target)\n",
        "\n",
        "    def forward(self, score, target):\n",
        "        if self.num_outputs == 1:\n",
        "            score = [score]\n",
        "\n",
        "        if len(self.balance_weights) == len(score):\n",
        "            return sum([w * self._forward(x, target) for (w, x) in zip(self.balance_weights, score)])\n",
        "        elif len(score) == 1:\n",
        "            return self.sb_weights * self._forward(score[0], target)\n",
        "        else:\n",
        "            raise ValueError(\"lengths of prediction and target are not identical!\")\n",
        "\n",
        "class OhemCrossEntropy(nn.Module):\n",
        "    def __init__(self, thres=0.7, min_kept=26_000, balance_weights=[0.4, 1.0], sb_weights=1.0, weight=None):\n",
        "        super(OhemCrossEntropy, self).__init__()\n",
        "        self.thresh = thres\n",
        "        self.min_kept = max(1, min_kept)\n",
        "        self.ignore_label = IGNORE_INDEX\n",
        "        self.balance_weights = balance_weights\n",
        "        self.sb_weights = sb_weights\n",
        "        self.criterion = nn.CrossEntropyLoss(\n",
        "            weight=weight,\n",
        "            ignore_index=self.ignore_label,\n",
        "            reduction='none'\n",
        "        )\n",
        "\n",
        "    def _ce_forward(self, score, target):\n",
        "        loss = self.criterion(score, target)\n",
        "        return loss\n",
        "\n",
        "    def _ohem_forward(self, score, target, **kwargs):\n",
        "        pred = F.softmax(score, dim=1)\n",
        "        pixel_losses = self.criterion(score, target).contiguous().view(-1)\n",
        "        mask = target.contiguous().view(-1) != self.ignore_label\n",
        "\n",
        "        tmp_target = target.clone()\n",
        "        tmp_target[tmp_target == self.ignore_label] = 0\n",
        "        pred = pred.gather(1, tmp_target.unsqueeze(1))\n",
        "        pred, ind = pred.contiguous().view(-1,)[mask].contiguous().sort()\n",
        "        min_value = pred[min(self.min_kept, pred.numel() - 1)]\n",
        "        threshold = max(min_value, self.thresh)\n",
        "\n",
        "        pixel_losses = pixel_losses[mask][ind]\n",
        "        pixel_losses = pixel_losses[pred < threshold]\n",
        "        return pixel_losses.mean()\n",
        "\n",
        "    def forward(self, score, target):\n",
        "        if not (isinstance(score, list) or isinstance(score, tuple)):\n",
        "            score = [score]\n",
        "\n",
        "        if len(self.balance_weights) == len(score):\n",
        "            functions = [self._ce_forward] * \\\n",
        "                (len(self.balance_weights) - 1) + [self._ohem_forward]\n",
        "            return sum([\n",
        "                w * func(x, target)\n",
        "                for (w, x, func) in zip(self.balance_weights, score, functions)\n",
        "            ])\n",
        "\n",
        "        elif len(score) == 1:\n",
        "            return self.sb_weights * self._ohem_forward(score[0], target)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"lengths of prediction and target are not identical!\")\n",
        "\n",
        "\n",
        "# Weighted Binary Cross Entropy per i bordi\n",
        "def weighted_bce(bd_pre, target):\n",
        "    n, c, h, w = bd_pre.size()\n",
        "    log_p = bd_pre.permute(0,2,3,1).contiguous().view(1, -1)\n",
        "    target_t = target.view(1, -1)\n",
        "\n",
        "    pos_index = (target_t == 1)\n",
        "    neg_index = (target_t == 0)\n",
        "\n",
        "    weight = torch.zeros_like(log_p)\n",
        "    pos_num = pos_index.sum()\n",
        "    neg_num = neg_index.sum()\n",
        "    sum_num = pos_num + neg_num\n",
        "    weight[pos_index] = neg_num * 1.0 / sum_num\n",
        "    weight[neg_index] = pos_num * 1.0 / sum_num\n",
        "\n",
        "    loss = F.binary_cross_entropy_with_logits(log_p, target_t, weight, reduction='mean')\n",
        "\n",
        "    return loss\n",
        "\n",
        "class BondaryLoss(nn.Module):\n",
        "    def __init__(self, coeff_bce = 20.0):\n",
        "        super(BondaryLoss, self).__init__()\n",
        "        self.coeff_bce = coeff_bce\n",
        "\n",
        "    def forward(self, bd_pre, bd_gt):\n",
        "        bce_loss = self.coeff_bce * weighted_bce(bd_pre, bd_gt)\n",
        "        loss = bce_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "# PIDNet Loss Totale\n",
        "class PIDNetLoss(nn.Module):\n",
        "    def __init__(self, lambda_0=0.4, lambda_1=20, lambda_2=1, lambda_3=1, threshold=0.8, class_weights=None):\n",
        "        super(PIDNetLoss, self).__init__()\n",
        "        self.class_weights = class_weights\n",
        "        if self.class_weights is not None:\n",
        "            self.class_weights = torch.tensor(class_weights).cuda()\n",
        "        if LOSS_TYPE == \"ohem\":\n",
        "          self.sem_loss = OhemCrossEntropy(balance_weights=[lambda_0, lambda_2], sb_weights=lambda_3, weight = self.class_weights)\n",
        "        else:\n",
        "          self.sem_loss = CrossEntropyLoss(num_outputs=2, balance_weights=[lambda_0, lambda_2], sb_weights=lambda_3, weight = self.class_weights)\n",
        "        self.bd_loss = BondaryLoss(coeff_bce=lambda_1)\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def forward(self, pred_p, pred_main, target, boundary_head, boundary_mask):\n",
        "        \"\"\"\n",
        "        pred_p: output branch P (B, C, H, W)\n",
        "        pred_main: output principale (B, C, H, W)\n",
        "        target: ground truth segmentazione (B, H, W)\n",
        "        boundary_head: predizione dei bordi (B, 1, H, W)\n",
        "        boundary_mask: ground truth dei bordi (B, 1, H, W)\n",
        "        \"\"\"\n",
        "\n",
        "        loss_s = self.sem_loss([pred_p, pred_main], target) # l_0 e l_2\n",
        "        loss_b = self.bd_loss(boundary_head, boundary_mask.unsqueeze(1)) # l_1\n",
        "\n",
        "        # l_3\n",
        "        filler = torch.ones_like(target) * IGNORE_INDEX\n",
        "        bd_label = torch.where(F.sigmoid(boundary_head[:,0,:,:])>self.threshold, target, filler)\n",
        "        loss_sb = self.sem_loss([pred_main], bd_label)\n",
        "\n",
        "\n",
        "        loss = loss_s + loss_b + loss_sb\n",
        "\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFsn22z-uQKS",
        "outputId": "bc2d2acb-4394-4fc4-e1f8-4f37edb90352"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X = torch.Size([16, 3, 512, 512])\n",
            "y = torch.Size([16, 512, 512])\n",
            "boundary = torch.Size([16, 512, 512])\n",
            "outputs[1] = torch.Size([16, 7, 512, 512])\n",
            "outputs[2] = torch.Size([16, 1, 512, 512])\n",
            "preds = torch.Size([16, 512, 512])\n",
            "unique values preds : tensor([0, 1, 2, 3, 4, 5, 6], device='cuda:0')\n",
            "unique values y : tensor([-1,  0,  1,  2,  3,  4,  5,  6], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "batch = next(iter(train_loader))  # (images, masks, boundaries)\n",
        "X, y, boundaries = batch  # Unpack the batch\n",
        "X = X.to(device)\n",
        "y = y.to(device)\n",
        "\n",
        "print(\"X =\", X.shape)\n",
        "print(\"y =\", y.shape)\n",
        "print(\"boundary =\", boundaries.shape)\n",
        "\n",
        "# Output del modello\n",
        "outputs = model(X)  # PIDNet può restituire [x_extra_p, x_, x_extra_d] se augment=True\n",
        "\n",
        "# Upscale trough bilinear interpolation -> riporto le dimensioni dell'output a quelli originali\n",
        "# Quindi passiamo da 64 x 64 a 512 x 512\n",
        "h, w = boundaries.size(1), boundaries.size(2)\n",
        "ph, pw = outputs[0].size(2), outputs[0].size(3)\n",
        "if ph != h or pw != w:\n",
        "    for i in range(len(outputs)):\n",
        "        outputs[i] = F.interpolate(outputs[i], size=(h, w), mode='bilinear', align_corners=True)\n",
        "\n",
        "pred_p, pred_main, boundary_head = outputs  # P, I, D branches\n",
        "\n",
        "#print(\"outputs[0] =\", outputs[0].shape) # pred_p\n",
        "print(\"outputs[1] =\", outputs[1].shape) # pred_main\n",
        "print(\"outputs[2] =\", outputs[2].shape) # Ramo D (boundary_head)\n",
        "\n",
        "preds = torch.argmax(pred_main, dim=1)\n",
        "print(\"preds =\", preds.shape)\n",
        "\n",
        "print(\"unique values preds :\", preds.unique())\n",
        "print(\"unique values y :\", y.unique())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjNWfPicTLQ3",
        "outputId": "9902e0e8-fc38-4c53-9fa4-8fc05f2f070f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/20: 100%|████████████████████████████████████████| 58/58 [00:13<00:00,  4.20it/s, loss=4.17]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Training Loss: 0.44231006313014676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 1 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 - Validation Loss: 0.38260196297715754 - mIoU: 0.10870762169361115 - mIoU per class Class 0: 0.4153, Class 1: 0.2379, Class 2: 0.0914, Class 3: 0.0000, Class 4: 0.0155, Class 5: 0.0009, Class 6: 0.0000\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/20: 100%|████████████████████████████████████████| 58/58 [00:12<00:00,  4.53it/s, loss=4.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20 - Training Loss: 0.28344388368967416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 2 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20 - Validation Loss: 0.3797024999346052 - mIoU: 0.12482450157403946 - mIoU per class Class 0: 0.3953, Class 1: 0.2718, Class 2: 0.1421, Class 3: 0.0010, Class 4: 0.0242, Class 5: 0.0377, Class 6: 0.0016\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/20: 100%|████████████████████████████████████████| 58/58 [00:12<00:00,  4.56it/s, loss=4.28]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20 - Training Loss: 0.2667586257006671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 3 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/20 - Validation Loss: 0.38790579172439904 - mIoU: 0.15301786363124847 - mIoU per class Class 0: 0.3923, Class 1: 0.2479, Class 2: 0.2341, Class 3: 0.0064, Class 4: 0.1453, Class 5: 0.0443, Class 6: 0.0008\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 4/20: 100%|████████████████████████████████████████| 58/58 [00:12<00:00,  4.54it/s, loss=4.09]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20 - Training Loss: 0.2572085666656494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 4 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/20 - Validation Loss: 0.37064857813186974 - mIoU: 0.1617031842470169 - mIoU per class Class 0: 0.4407, Class 1: 0.2500, Class 2: 0.2238, Class 3: 0.0379, Class 4: 0.1334, Class 5: 0.0447, Class 6: 0.0014\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/20: 100%|████████████████████████████████████████| 58/58 [00:12<00:00,  4.53it/s, loss=4.32]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20 - Training Loss: 0.24978266174728805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 5 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/20 - Validation Loss: 0.36268490836733863 - mIoU: 0.18438135087490082 - mIoU per class Class 0: 0.4314, Class 1: 0.3128, Class 2: 0.2752, Class 3: 0.0493, Class 4: 0.1357, Class 5: 0.0831, Class 6: 0.0032\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 6/20: 100%|████████████████████████████████████████| 58/58 [00:12<00:00,  4.53it/s, loss=4.33]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20 - Training Loss: 0.24392298956175107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 6 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/20 - Validation Loss: 0.35737433165182797 - mIoU: 0.19164222478866577 - mIoU per class Class 0: 0.4334, Class 1: 0.3162, Class 2: 0.2737, Class 3: 0.1157, Class 4: 0.1172, Class 5: 0.0818, Class 6: 0.0034\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 7/20: 100%|█████████████████████████████████████████| 58/58 [00:12<00:00,  4.54it/s, loss=3.7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20 - Training Loss: 0.2380045950090563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 7 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/20 - Validation Loss: 0.3727001111744802 - mIoU: 0.20984670519828796 - mIoU per class Class 0: 0.4288, Class 1: 0.2962, Class 2: 0.2683, Class 3: 0.0733, Class 4: 0.2742, Class 5: 0.1264, Class 6: 0.0019\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/20: 100%|████████████████████████████████████████| 58/58 [00:12<00:00,  4.53it/s, loss=4.63]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20 - Training Loss: 0.23398834408940497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 8 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/20 - Validation Loss: 0.3899387405032203 - mIoU: 0.19293802976608276 - mIoU per class Class 0: 0.4039, Class 1: 0.3060, Class 2: 0.2993, Class 3: 0.0547, Class 4: 0.2427, Class 5: 0.0411, Class 6: 0.0029\n",
            "[0.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 9/20: 100%|████████████████████████████████████████| 58/58 [00:12<00:00,  4.54it/s, loss=3.76]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20 - Training Loss: 0.23041925791147594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 9 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/20 - Validation Loss: 0.35487962491584546 - mIoU: 0.22538268566131592 - mIoU per class Class 0: 0.4454, Class 1: 0.3171, Class 2: 0.3029, Class 3: 0.1628, Class 4: 0.2680, Class 5: 0.0580, Class 6: 0.0234\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/20: 100%|████████████████████████████████████████| 58/58 [00:12<00:00,  4.53it/s, loss=3.7]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20 - Training Loss: 0.2250412384239403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 10 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/20 - Validation Loss: 0.3597588704261945 - mIoU: 0.23404395580291748 - mIoU per class Class 0: 0.4194, Class 1: 0.3370, Class 2: 0.3176, Class 3: 0.1330, Class 4: 0.2898, Class 5: 0.0974, Class 6: 0.0442\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 11/20: 100%|███████████████████████████████████████| 58/58 [00:12<00:00,  4.53it/s, loss=3.97]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20 - Training Loss: 0.2245896071356696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 11 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20 - Validation Loss: 0.3651451569098931 - mIoU: 0.2231387346982956 - mIoU per class Class 0: 0.4252, Class 1: 0.3178, Class 2: 0.3024, Class 3: 0.0665, Class 4: 0.2102, Class 5: 0.1861, Class 6: 0.0537\n",
            "[0.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 12/20: 100%|███████████████████████████████████████| 58/58 [00:12<00:00,  4.53it/s, loss=3.51]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20 - Training Loss: 0.22069960078677617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 12 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/20 - Validation Loss: 0.3456984619041542 - mIoU: 0.24292951822280884 - mIoU per class Class 0: 0.4279, Class 1: 0.3515, Class 2: 0.3482, Class 3: 0.0493, Class 4: 0.2016, Class 5: 0.2621, Class 6: 0.0600\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/20: 100%|███████████████████████████████████████| 58/58 [00:12<00:00,  4.54it/s, loss=3.58]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20 - Training Loss: 0.21824491939029178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 13 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/20 - Validation Loss: 0.3425755831070277 - mIoU: 0.2520464062690735 - mIoU per class Class 0: 0.4522, Class 1: 0.3549, Class 2: 0.3479, Class 3: 0.1573, Class 4: 0.2004, Class 5: 0.2071, Class 6: 0.0446\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 14/20: 100%|███████████████████████████████████████| 58/58 [00:12<00:00,  4.52it/s, loss=3.24]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20 - Training Loss: 0.21315990731522844\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 14 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/20 - Validation Loss: 0.33083796810794186 - mIoU: 0.278806209564209 - mIoU per class Class 0: 0.4542, Class 1: 0.3747, Class 2: 0.3742, Class 3: 0.1256, Class 4: 0.3215, Class 5: 0.2264, Class 6: 0.0751\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 15/20: 100%|████████████████████████████████████████| 58/58 [00:12<00:00,  4.51it/s, loss=3.2]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20 - Training Loss: 0.21207214303918787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 15 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/20 - Validation Loss: 0.3395688853738628 - mIoU: 0.28028321266174316 - mIoU per class Class 0: 0.4334, Class 1: 0.3579, Class 2: 0.3628, Class 3: 0.2274, Class 4: 0.3555, Class 5: 0.1609, Class 6: 0.0641\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 16/20: 100%|███████████████████████████████████████| 58/58 [00:12<00:00,  4.52it/s, loss=3.19]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20 - Training Loss: 0.21166895531319282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 16 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/20 - Validation Loss: 0.3439653074586546 - mIoU: 0.23466765880584717 - mIoU per class Class 0: 0.3783, Class 1: 0.3723, Class 2: 0.3566, Class 3: 0.1200, Class 4: 0.1583, Class 5: 0.2284, Class 6: 0.0288\n",
            "[0.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/20: 100%|███████████████████████████████████████| 58/58 [00:12<00:00,  4.52it/s, loss=3.76]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20 - Training Loss: 0.20837611481950088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 17 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/20 - Validation Loss: 0.3198267144042176 - mIoU: 0.3198903501033783 - mIoU per class Class 0: 0.4628, Class 1: 0.3853, Class 2: 0.3904, Class 3: 0.2465, Class 4: 0.2471, Class 5: 0.3329, Class 6: 0.1742\n",
            "[0.01]\n",
            "Modello con miou migliore salvato: /content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 18/20: 100%|██████████████████████████████████████████| 58/58 [00:12<00:00,  4.51it/s, loss=4]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20 - Training Loss: 0.20876139563483162\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 18 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/20 - Validation Loss: 0.3219019097167176 - mIoU: 0.29841873049736023 - mIoU per class Class 0: 0.4549, Class 1: 0.3874, Class 2: 0.4131, Class 3: 0.0962, Class 4: 0.2841, Class 5: 0.3464, Class 6: 0.1069\n",
            "[0.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 19/20: 100%|███████████████████████████████████████| 58/58 [00:12<00:00,  4.54it/s, loss=2.86]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20 - Training Loss: 0.20601653717659615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 19 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/20 - Validation Loss: 0.33687832861235645 - mIoU: 0.30619508028030396 - mIoU per class Class 0: 0.4628, Class 1: 0.3737, Class 2: 0.3708, Class 3: 0.2983, Class 4: 0.2595, Class 5: 0.2575, Class 6: 0.1207\n",
            "[0.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/20: 100%|███████████████████████████████████████| 58/58 [00:12<00:00,  4.53it/s, loss=3.31]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20 - Training Loss: 0.20206305168770455\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Epoch 20 [Validation]: 100%|██████████| 15/15 [00:04<00:00,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/20 - Validation Loss: 0.34909849249439323 - mIoU: 0.26364779472351074 - mIoU per class Class 0: 0.4570, Class 1: 0.3499, Class 2: 0.3719, Class 3: 0.2676, Class 4: 0.1215, Class 5: 0.2220, Class 6: 0.0557\n",
            "[0.01]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torchmetrics.segmentation import MeanIoU\n",
        "import torch.nn.functional as F\n",
        "\n",
        "os.makedirs(\"/content/drive/MyDrive/AML_project/checkpoints\", exist_ok=True)\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "\n",
        "record_miou = None\n",
        "\n",
        "num_classes = 7  # Cambia in base al tuo dataset\n",
        "miou_classes = MeanIoU(num_classes=num_classes, input_format = \"index\", per_class=True).to(device)\n",
        "loss_fn = PIDNetLoss()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "\n",
        "    total_train_samples = 0\n",
        "\n",
        "    batch_pbar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{EPOCHS}\", ncols=100)\n",
        "\n",
        "    for batch, (X, y, boundary_mask) in batch_pbar:\n",
        "        X = X.to(device)\n",
        "        y = y.to(device)\n",
        "        boundary_mask = boundary_mask.to(device)\n",
        "\n",
        "        # Output del modello\n",
        "        outputs = model(X)  # PIDNet può restituire [x_extra_p, x_, x_extra_d] se augment=True\n",
        "\n",
        "        # Upscale trough bilinear interpolation -> riporto le dimensioni dell'output a quelli originali\n",
        "        # Quindi passiamo da 64 x 64 della rete a 512 x 512\n",
        "        h, w = boundary_mask.size(1), boundary_mask.size(2)\n",
        "        ph, pw = outputs[0].size(2), outputs[0].size(3)\n",
        "        if ph != h or pw != w:\n",
        "            for i in range(len(outputs)):\n",
        "                outputs[i] = F.interpolate(outputs[i], size=(h, w), mode='bilinear', align_corners=True)\n",
        "\n",
        "        if model.augment:\n",
        "            pred_p, pred_main, boundary_head = outputs  # P, I, D branches\n",
        "        else:\n",
        "            pred_main = outputs\n",
        "            boundary_head = None  # Nessuna branch D se augment=False\n",
        "\n",
        "        # Calcolo della loss\n",
        "        loss = loss_fn(pred_p, pred_main, y, boundary_head, boundary_mask)\n",
        "\n",
        "        if LOSS_TYPE == \"ohem\":\n",
        "              loss = torch.mean(loss)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_samples += X.size(0)\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        batch_pbar.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = train_loss / total_train_samples\n",
        "\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Training Loss: {avg_train_loss}\")\n",
        "\n",
        "    # **Validazione**\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    miou_classes.reset()\n",
        "    total_val_samples = 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "      pbar_val = tqdm(enumerate(val_loader), total=len(val_loader), desc=f\"Epoch {epoch+1} [Validation]\")\n",
        "\n",
        "      for batch, (X_val, y_val, boundary_mask) in pbar_val:\n",
        "          X_val = X_val.to(device)\n",
        "          y_val = y_val.to(device)\n",
        "          boundary_mask = boundary_mask.to(device)\n",
        "\n",
        "          # Output del modello\n",
        "          outputs = model(X_val)\n",
        "\n",
        "          ## Upscale trough bilinear interpolation\n",
        "          h, w = boundary_mask.size(1), boundary_mask.size(2)\n",
        "          ph, pw = outputs[0].size(2), outputs[0].size(3)\n",
        "          if ph != h or pw != w:\n",
        "              for i in range(len(outputs)):\n",
        "                  outputs[i] = F.interpolate(outputs[i], size=(h, w), mode='bilinear', align_corners=True)\n",
        "\n",
        "          if model.augment:\n",
        "              pred_p, pred_main, boundary_head = outputs\n",
        "          else:\n",
        "              pred_main = outputs\n",
        "              boundary_head = None\n",
        "\n",
        "          # Calcola la loss\n",
        "          loss = loss_fn(pred_p, pred_main, y_val, boundary_head, boundary_mask)\n",
        "\n",
        "          if LOSS_TYPE == \"ohem\":\n",
        "            loss = torch.mean(loss)\n",
        "\n",
        "          val_loss += loss.item()\n",
        "\n",
        "          total_val_samples += X_val.size(0)\n",
        "\n",
        "          # Calcola le predizioni\n",
        "          preds = pred_main.argmax(dim=1)  # Shape: (N, H, W)\n",
        "\n",
        "          # Mask dei pixel validi (classi da 0 a num_classes - 1)\n",
        "          valid_mask = (y_val >= 0) & (y_val < num_classes)\n",
        "\n",
        "          # Appiattisci le predizioni e i target solo sui pixel validi\n",
        "          preds_flat = preds[valid_mask]\n",
        "          targets_flat = y_val[valid_mask]\n",
        "\n",
        "          miou_classes.update(preds_flat, targets_flat)\n",
        "\n",
        "    avg_val_loss = val_loss / total_val_samples\n",
        "\n",
        "    miou_per_class = miou_classes.compute()  # Returns a tensor with per-class IoU\n",
        "    miou = miou_per_class.mean()\n",
        "\n",
        "    miou_per_class_str = \", \".join([f\"Class {i}: {iou:.4f}\" for i, iou in enumerate(miou_per_class)])\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} - Validation Loss: {avg_val_loss} - mIoU: {miou} - mIoU per class {miou_per_class_str}\")\n",
        "\n",
        "    print(scheduler.get_last_lr())\n",
        "\n",
        "    if record_miou is None or miou > record_miou:\n",
        "        best_model_path = f\"/content/drive/MyDrive/AML_project/checkpoints/best_model_PIDNET_5_CUT_split.pth\"\n",
        "        torch.save(model.state_dict(), best_model_path)\n",
        "        print(f\"Modello con miou migliore salvato: {best_model_path}\")\n",
        "        record_miou = miou\n",
        "\n",
        "    ## steps the scheduler\n",
        "    if PLATEAU:\n",
        "      scheduler.step(miou)\n",
        "    else:\n",
        "      scheduler.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "tBEUaAllBcEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "  class MODEL:\n",
        "      NAME = 'pidnet_s'\n",
        "      PRETRAINED = 'PIDNet_S_ImageNet.pth.tar'\n",
        "  class DATASET:\n",
        "      NUM_CLASSES = NUM_CLASSES\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "model = get_seg_model(cfg, imgnet_pretrained=True)\n",
        "\n",
        "best_model_weights = torch.load(best_model_path)\n",
        "\n",
        "try:\n",
        "  model.load_state_dict(torch.load(best_model_path))\n",
        "except:\n",
        "  print(list(torch.load(best_model_path).keys())[:5])\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "model.augment"
      ],
      "metadata": {
        "id": "IS3XcKqoKXJ3",
        "outputId": "d4278df6-86b7-492e-a0b3-ca70c0d5b8ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_loss = 0\n",
        "miou_classes.reset()\n",
        "\n",
        "total_test_samples = 0\n",
        "\n",
        "with torch.inference_mode():\n",
        "    for X_test, y_test, boundary_mask in test_loader:\n",
        "        X_test = X_test.to(device)\n",
        "        y_test = y_test.to(device)\n",
        "        boundary_mask = boundary_mask.to(device)\n",
        "\n",
        "        # Output del modello\n",
        "        outputs = model(X_test)\n",
        "\n",
        "        ## Upscale trough bilinear interpolation\n",
        "        h, w = boundary_mask.size(1), boundary_mask.size(2)\n",
        "        if model.augment:\n",
        "          ph, pw = outputs[0].size(2), outputs[0].size(3)\n",
        "        else:\n",
        "          ph, pw = outputs.size(2), outputs.size(3)\n",
        "        if ph != h or pw != w:\n",
        "            if model.augment:\n",
        "              for i in range(len(outputs)):\n",
        "                  outputs[i] = F.interpolate(outputs[i], size=(h, w), mode='bilinear', align_corners=True)\n",
        "            else:\n",
        "              outputs = F.interpolate(outputs, size=(h, w), mode='bilinear', align_corners=True)\n",
        "\n",
        "        if model.augment:\n",
        "            pred_p, pred_main, boundary_head = outputs\n",
        "        else:\n",
        "            pred_main = outputs\n",
        "            boundary_head = None\n",
        "\n",
        "        # Calcola la loss\n",
        "        loss = loss_fn(pred_p, pred_main, y_test, boundary_head, boundary_mask)\n",
        "\n",
        "        if LOSS_TYPE == \"ohem\":\n",
        "            loss = torch.mean(loss)\n",
        "\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        total_test_samples += X_test.size(0)\n",
        "\n",
        "        # Calcola le predizioni\n",
        "        preds = pred_main.argmax(dim=1)  # Shape: (N, H, W)\n",
        "\n",
        "        # Mask dei pixel validi (classi da 0 a num_classes - 1)\n",
        "        valid_mask = (y_test >= 0) & (y_test < num_classes)\n",
        "\n",
        "        # Appiattisci le predizioni e i target solo sui pixel validi\n",
        "        preds_flat = preds[valid_mask]\n",
        "        targets_flat = y_test[valid_mask]\n",
        "\n",
        "        miou_classes.update(preds_flat, targets_flat)\n",
        "\n",
        "avg_test_loss = test_loss / total_test_samples\n",
        "\n",
        "miou_per_class = miou_classes.compute()  # Returns a tensor with per-class IoU\n",
        "miou = miou_per_class.mean()\n",
        "\n",
        "miou_per_class_str = \", \".join([f\"Class {i}: {iou:.4f}\" for i, iou in enumerate(miou_per_class)])\n",
        "print(f\" Test Loss: {avg_test_loss} - mIoU: {miou} - mIoU per class {miou_per_class_str}\")"
      ],
      "metadata": {
        "id": "uZJNslWx67BV",
        "outputId": "086602ce-b1cd-4840-c6f3-c6b43460b080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Test Loss: 0.4761841768218625 - mIoU: 0.13392117619514465 - mIoU per class Class 0: 0.3751, Class 1: 0.1092, Class 2: 0.1920, Class 3: 0.1273, Class 4: 0.0434, Class 5: 0.0215, Class 6: 0.0690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance\n"
      ],
      "metadata": {
        "id": "_rXI7eVx2TMd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bRByJkGflhLX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "978a630b-cd28-4289-963c-0ded1263b03c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom timeit import default_timer as timer\\nimport matplotlib.pyplot as plt\\nfrom fvcore.nn import FlopCountAnalysis\\nimport torch.nn.functional as F\\nimport random\\n\\nmodel.eval()  # Set model to evaluation mode\\n\\nwith torch.inference_mode():\\n    # Prendi un\\'immagine random dal validation set\\n    random_index = random.randint(0, len(test_dataset) - 1)\\n    X, y, boundary_mask = test_dataset[random_index]\\n\\n    X = X.to(device).unsqueeze(dim=0)  # Aggiunge la dimensione batch\\n    y = y.to(device).unsqueeze(dim=0)\\n    boundary_mask = boundary_mask.to(device).unsqueeze(dim=0)\\n\\n    start = timer()\\n    outputs = model(X)\\n    end = timer()\\n\\n    latency = end - start\\n\\n    ## Upscale trough bilinear interpolation\\n    h, w = boundary_mask.size(1), boundary_mask.size(2)\\n    ph, pw = outputs[0].size(2), outputs[0].size(3)\\n    if ph != h or pw != w:\\n        for i in range(len(outputs)):\\n            outputs[i] = F.interpolate(outputs[i], size=(h, w), mode=\\'bilinear\\', align_corners=True)\\n\\n    # Se augment=True, gestiamo i diversi output\\n    if model.augment:\\n        pred_p, pred_main, boundary_head = outputs\\n    else:\\n        pred_main = outputs\\n        boundary_head = None\\n\\n    # Calcolo dei FLOPs\\n    flops = FlopCountAnalysis(model, X.clone())\\n\\n    # Softmax per normalizzare le predizioni\\n    normalized_masks = torch.nn.functional.softmax(pred_main, dim=1)\\n\\n    # Selezione delle predizioni per ciascuna classe\\n    masks = [\\n        normalized_masks[0, sem_class_to_idx[cls]]\\n        for cls in SEM_CLASSES\\n    ]\\n\\n    print(\"*********\")\\n    print(f\"FLOPs: {flops.total() / 1e9:.3f} GFLOPs\")\\n    print(f\"Average inference latency is {latency:.3f} seconds.\")\\n\\n    # Converti output e ground truth per la visualizzazione\\n    out = pred_main.squeeze().argmax(dim=0).cpu().numpy()  # Output segmentazione\\n    y_np = y.squeeze().cpu().numpy()  # Ground truth\\n    X_np = X.squeeze().cpu().permute(1, 2, 0).numpy()  # Immagine originale\\n\\n    # Creazione della figura con tre immagini affiancate\\n    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\\n\\n    # Immagine originale\\n    axes[0].imshow(X_np)\\n    axes[0].set_title(\"Original Image\")\\n    axes[0].axis(\"off\")\\n\\n    # Predizione del modello\\n    axes[1].imshow(out, cmap=\"gray\")\\n    axes[1].set_title(\"Predicted Segmentation\")\\n    axes[1].axis(\"off\")\\n\\n    # Ground truth\\n    axes[2].imshow(y_np, cmap=\"gray\")\\n    axes[2].set_title(\"Ground Truth\")\\n    axes[2].axis(\"off\")\\n\\n    plt.show()\\n\\n    # Conta i parametri del modello\\n    params = sum(p.numel() for p in model.parameters())\\n    print(f\"Params: {params / 1e6:.3f} M\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "\"\"\"\n",
        "from timeit import default_timer as timer\n",
        "import matplotlib.pyplot as plt\n",
        "from fvcore.nn import FlopCountAnalysis\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "with torch.inference_mode():\n",
        "    # Prendi un'immagine random dal validation set\n",
        "    random_index = random.randint(0, len(test_dataset) - 1)\n",
        "    X, y, boundary_mask = test_dataset[random_index]\n",
        "\n",
        "    X = X.to(device).unsqueeze(dim=0)  # Aggiunge la dimensione batch\n",
        "    y = y.to(device).unsqueeze(dim=0)\n",
        "    boundary_mask = boundary_mask.to(device).unsqueeze(dim=0)\n",
        "\n",
        "    start = timer()\n",
        "    outputs = model(X)\n",
        "    end = timer()\n",
        "\n",
        "    latency = end - start\n",
        "\n",
        "    ## Upscale trough bilinear interpolation\n",
        "    h, w = boundary_mask.size(1), boundary_mask.size(2)\n",
        "    ph, pw = outputs[0].size(2), outputs[0].size(3)\n",
        "    if ph != h or pw != w:\n",
        "        for i in range(len(outputs)):\n",
        "            outputs[i] = F.interpolate(outputs[i], size=(h, w), mode='bilinear', align_corners=True)\n",
        "\n",
        "    # Se augment=True, gestiamo i diversi output\n",
        "    if model.augment:\n",
        "        pred_p, pred_main, boundary_head = outputs\n",
        "    else:\n",
        "        pred_main = outputs\n",
        "        boundary_head = None\n",
        "\n",
        "    # Calcolo dei FLOPs\n",
        "    flops = FlopCountAnalysis(model, X.clone())\n",
        "\n",
        "    # Softmax per normalizzare le predizioni\n",
        "    normalized_masks = torch.nn.functional.softmax(pred_main, dim=1)\n",
        "\n",
        "    # Selezione delle predizioni per ciascuna classe\n",
        "    masks = [\n",
        "        normalized_masks[0, sem_class_to_idx[cls]]\n",
        "        for cls in SEM_CLASSES\n",
        "    ]\n",
        "\n",
        "    print(\"*********\")\n",
        "    print(f\"FLOPs: {flops.total() / 1e9:.3f} GFLOPs\")\n",
        "    print(f\"Average inference latency is {latency:.3f} seconds.\")\n",
        "\n",
        "    # Converti output e ground truth per la visualizzazione\n",
        "    out = pred_main.squeeze().argmax(dim=0).cpu().numpy()  # Output segmentazione\n",
        "    y_np = y.squeeze().cpu().numpy()  # Ground truth\n",
        "    X_np = X.squeeze().cpu().permute(1, 2, 0).numpy()  # Immagine originale\n",
        "\n",
        "    # Creazione della figura con tre immagini affiancate\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Immagine originale\n",
        "    axes[0].imshow(X_np)\n",
        "    axes[0].set_title(\"Original Image\")\n",
        "    axes[0].axis(\"off\")\n",
        "\n",
        "    # Predizione del modello\n",
        "    axes[1].imshow(out, cmap=\"gray\")\n",
        "    axes[1].set_title(\"Predicted Segmentation\")\n",
        "    axes[1].axis(\"off\")\n",
        "\n",
        "    # Ground truth\n",
        "    axes[2].imshow(y_np, cmap=\"gray\")\n",
        "    axes[2].set_title(\"Ground Truth\")\n",
        "    axes[2].axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    # Conta i parametri del modello\n",
        "    params = sum(p.numel() for p in model.parameters())\n",
        "    print(f\"Params: {params / 1e6:.3f} M\")\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4",
      "collapsed_sections": [
        "aRC4KXtmj3Pi"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}