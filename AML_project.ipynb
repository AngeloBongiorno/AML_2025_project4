{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngeloBongiorno/AML_2025_project4/blob/angelo/AML_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7QJviwzoN5m"
      },
      "source": [
        "## Install Dependency & DeepLab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHpwU5g8s-Pt"
      },
      "source": [
        "## Upload .zip files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2_aVBiH46K3"
      },
      "source": [
        "For this step you must have the zip files in your Drive into a folder called `AML_project`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "!pip install fvcore"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xxVbeep6Rlnb",
        "outputId": "7ce0c828-343f-4496-8ffc-26030d962151"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.14.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.11/dist-packages (0.1.5.post20221221)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.0.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.11/dist-packages (from fvcore) (2.5.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from fvcore) (11.1.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.9.0)\n",
            "Requirement already satisfied: iopath>=0.1.7 in /usr/local/lib/python3.11/dist-packages (from fvcore) (0.1.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (4.12.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from iopath>=0.1.7->fvcore) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8lChuFCsmFi",
        "outputId": "1cae29ba-ff50-4312-b33d-2cf0ddd8d1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AML_2025_project4' already exists and is not an empty directory.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "!git clone -b angelo --single-branch https://github.com/AngeloBongiorno/AML_2025_project4.git\n",
        "\n",
        "!cp AML_2025_project4/utils.py .\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laEb8KOytCpo",
        "outputId": "0ed5e8c0-d8c9-464b-f912-4dabad6b1240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping extraction for training, already extracted.\n",
            "Skipping extraction for validation, already extracted.\n",
            "Extraction check completed!\n"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# ZIP files paths on Google Drive\n",
        "zip_files = {\n",
        "    \"training\": \"/content/drive/My Drive/AML_project/Train.zip\",\n",
        "    \"validation\": \"/content/drive/My Drive/AML_project/Val.zip\",\n",
        "    #\"test\": \"/content/drive/My Drive/AML_project/Test.zip\"\n",
        "}\n",
        "\n",
        "# Destination directory on Colab\n",
        "extract_path = \"/content/dataset\"\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "\n",
        "for name, zip_path in zip_files.items():\n",
        "    extract_dir = f\"{extract_path}/{name}\"\n",
        "\n",
        "    # Check if the directory is non-empty (assumes extraction is complete if the folder has files)\n",
        "    if os.path.exists(extract_dir) and any(os.scandir(extract_dir)):\n",
        "        print(f\"Skipping extraction for {name}, already extracted.\")\n",
        "    else:\n",
        "        print(f\"Extracting {name}...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "        print(f\"{name} extracted!\")\n",
        "\n",
        "print(\"Extraction check completed!\")\n",
        "\n",
        "TRAINING_PATH_URBAN = os.path.join(extract_path, \"training\", \"Train\", \"Urban\")\n",
        "TRAINING_PATH_RURAL = os.path.join(extract_path, \"training\", \"Train\", \"Rural\")\n",
        "#TEST_PATH_URBAN = os.path.join(extract_path, \"test\", \"Test\", \"Urban\")\n",
        "#TEST_PATH_RURAL = os.path.join(extract_path, \"test\", \"Test\", \"Rural\")\n",
        "VAL_PATH_URBAN = os.path.join(extract_path, \"validation\", \"Val\", \"Urban\")\n",
        "VAL_PATH_RURAL = os.path.join(extract_path, \"validation\", \"Val\", \"Rural\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrjECeMs7Sc5"
      },
      "source": [
        "## Load DeepLab v2 PreTrained Weight"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crea la cartella model e inserisce il modello DeepLabv2\n"
      ],
      "metadata": {
        "id": "sR3Z1csCiZ60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "models_dir = Path(\"models\")\n",
        "deeplab_file = models_dir / \"DeepLab_v2.py\"\n",
        "\n",
        "models_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if deeplab_file.is_file():\n",
        "    print(\"DeepLab-v2.py already exists in 'models/' folder, skipping download.\")\n",
        "else:\n",
        "    print(\"Downloading DeepLab-v2.py to 'models/' folder.\")\n",
        "\n",
        "    url = \"https://raw.githubusercontent.com/Gabrysse/MLDL2024_project1/refs/heads/master/models/deeplabv2/deeplabv2.py\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        with open(deeplab_file, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "        print(\"Download completed successfully!\")\n",
        "    else:\n",
        "        print(f\"Failed to download file. HTTP Status Code: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYBJp19mMan8",
        "outputId": "9f741d00-d2d7-4cac-d68d-9d7ba4f22d57"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepLab-v2.py already exists in 'models/' folder, skipping download.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "models_dir = Path(\"models\")\n",
        "sys.path.append(str(models_dir))\n",
        "\n",
        "from DeepLab_v2 import get_deeplab_v2  # Esempio di import di una funzione\n"
      ],
      "metadata": {
        "id": "fiVP4lOOO_e8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementazione del dataloader"
      ],
      "metadata": {
        "id": "dw9SYUCgi6us"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "T6kSW8hGjAo9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "RESIZE = (512, 512)\n",
        "\n",
        "SEM_CLASSES = [\n",
        "    'background',\n",
        "    'building',\n",
        "    'road',\n",
        "    'water',\n",
        "    'barren',\n",
        "    'forest',\n",
        "    'agriculture'\n",
        "]\n",
        "\n",
        "NUM_CLASSES = len(SEM_CLASSES)\n",
        "\n",
        "sem_class_to_idx = {cls: idx for (idx, cls) in enumerate(SEM_CLASSES)}\n",
        "\n",
        "\n",
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None, target_transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.image_filenames = sorted(os.listdir(image_dir))\n",
        "        self.mask_filenames = sorted(os.listdir(mask_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_filenames[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.mask_filenames[idx])\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")  # Assicura che sia RGB\n",
        "        mask = Image.open(mask_path).convert(\"L\")  # Converti la maschera in scala di grigi (1 canale)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.target_transform:\n",
        "          mask = self.target_transform(mask)\n",
        "\n",
        "        mask = torch.as_tensor(np.array(mask), dtype=torch.int64) - 1\n",
        "\n",
        "        return image, mask  # Return (image, mask) pair\n",
        "\n",
        "# Define transformations for images & masks\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.Resize(RESIZE, interpolation=Image.BILINEAR),  # Resize images to 256x256\n",
        "    transforms.ToTensor(),  # Convert image to tensor\n",
        "])\n",
        "\n",
        "mask_transform = transforms.Compose([\n",
        "    transforms.Resize(RESIZE, interpolation=Image.NEAREST),  # Resize masks to 256x256\n",
        "])\n",
        "\n",
        "# Create dataset objects\n",
        "train_dataset_urban = SegmentationDataset(TRAINING_PATH_URBAN + \"/images_png\", TRAINING_PATH_URBAN + \"/masks_png\",\n",
        "                                    transform=image_transform, target_transform=mask_transform)\n",
        "val_dataset_urban = SegmentationDataset(VAL_PATH_URBAN + \"/images_png\", VAL_PATH_URBAN + \"/masks_png\",\n",
        "                                  transform=image_transform, target_transform= mask_transform)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset_urban, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset_urban, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dAOHY95Q7Tl8",
        "outputId": "349ecc56-88f0-4ea0-dac3-d3a002860aa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Deeplab pretraining loading...\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "# Aggiungi la cartella che contiene 'models' al sys.path\n",
        "sys.path.append(str(Path('/content/deeplab-pytorch/deeplab-pytorch/MLDL2024_project1/test')))\n",
        "\n",
        "# Path of the model\n",
        "model_path = Path(\"/content/drive/MyDrive/AML_project/deeplab_resnet_pretrained_imagenet.pth\")\n",
        "\n",
        "# Loading the model using DeepLab v2\n",
        "model = get_deeplab_v2(num_classes=NUM_CLASSES, pretrain=True, pretrain_model_path=model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSQUcy7_t2of"
      },
      "source": [
        "## Training Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAbmz5Cz4I4H",
        "outputId": "c07f8784-b907-4d0f-83f8-565b984cfcfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zCKqjLctlmFC"
      },
      "outputs": [],
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index= -1)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3x4vYHX5p_dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d5be8f-1364-4b5e-d5dd-dd6b858106f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | Training Loss: 1.5940611169144914 | Validation Loss: 431.6046572598544 | mIoU: 0.1370\n",
            "Epoch 2/20 | Training Loss: 1.5028317232389707 | Validation Loss: 2.8932714353908193 | mIoU: 0.0065\n",
            "Epoch 3/20 | Training Loss: 1.4178824166993838 | Validation Loss: 2.6257660497318613 | mIoU: 0.0086\n",
            "Epoch 4/20 | Training Loss: 1.374615881894086 | Validation Loss: 2.372098998589949 | mIoU: 0.0881\n",
            "Epoch 5/20 | Training Loss: 1.3411206329191052 | Validation Loss: 2.221284356984225 | mIoU: 0.1918\n",
            "Epoch 6/20 | Training Loss: 1.2960348387022276 | Validation Loss: 2.2425508932633833 | mIoU: 0.2013\n",
            "Epoch 7/20 | Training Loss: 1.2652118657086346 | Validation Loss: 2.2654813636432993 | mIoU: 0.1770\n",
            "Epoch 8/20 | Training Loss: 1.2345074028582186 | Validation Loss: 2.353178761222146 | mIoU: 0.0965\n",
            "Epoch 9/20 | Training Loss: 1.1882221956510801 | Validation Loss: 2.1574360619891775 | mIoU: 0.2336\n",
            "Epoch 10/20 | Training Loss: 1.1591724318427008 | Validation Loss: 2.26748695156791 | mIoU: 0.1787\n",
            "Epoch 11/20 | Training Loss: 1.132465446317518 | Validation Loss: 2.0799681435931814 | mIoU: 0.1951\n",
            "Epoch 12/20 | Training Loss: 1.1006104768933476 | Validation Loss: 2.279505794698542 | mIoU: 0.2041\n",
            "Epoch 13/20 | Training Loss: 1.0721193697001483 | Validation Loss: 2.3121525157581675 | mIoU: 0.1496\n",
            "Epoch 14/20 | Training Loss: 1.0444637601440017 | Validation Loss: 2.3078385158018633 | mIoU: 0.2309\n",
            "Epoch 15/20 | Training Loss: 1.0492170630274593 | Validation Loss: 2.4330138835040005 | mIoU: 0.1216\n",
            "Epoch 16/20 | Training Loss: 1.0171872119645815 | Validation Loss: 2.5008119453083384 | mIoU: 0.1133\n",
            "Epoch 17/20 | Training Loss: 1.0043533750482507 | Validation Loss: 2.319719834761186 | mIoU: 0.2000\n",
            "Epoch 18/20 | Training Loss: 0.9910794206567712 | Validation Loss: 2.611476844007319 | mIoU: 0.1137\n",
            "Epoch 19/20 | Training Loss: 0.9791641638085649 | Validation Loss: 2.4947403127496894 | mIoU: 0.1762\n",
            "Epoch 20/20 | Training Loss: 0.965899105007584 | Validation Loss: 2.431085705757141 | mIoU: 0.2194\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torchmetrics.segmentation import MeanIoU\n",
        "\n",
        "from utils import train_step, validation_step\n",
        "\n",
        "os.makedirs(\"/content/drive/MyDrive/AML_project/checkpoints\", exist_ok=True)\n",
        "\n",
        "EPOCHS = 20\n",
        "torch.manual_seed(42)\n",
        "\n",
        "miou = MeanIoU(num_classes=NUM_CLASSES).to(device)\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "  avg_train_loss = train_step(model=model,\n",
        "               optimizer=optimizer,\n",
        "               loss_fn=loss_fn,\n",
        "               train_loader=train_loader,\n",
        "               device=device,\n",
        "               epoch=epoch,\n",
        "               EPOCHS=EPOCHS\n",
        "               )\n",
        "\n",
        "    # Valutazione del modello\n",
        "\n",
        "  avg_val_loss, miou_score = validation_step(model=model,\n",
        "                                             val_loader=val_loader,\n",
        "                                             loss_fn=loss_fn,\n",
        "                                             device=device,\n",
        "                                             miou=miou)\n",
        "\n",
        "  print(f\"Epoch {epoch+1}/{EPOCHS} | Training Loss: {avg_train_loss} | Validation Loss: {avg_val_loss} | mIoU: {miou_score:.4f}\")\n",
        "\n",
        "  \"\"\"\n",
        "  # Salva il modello ogni 2 epoche\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "      checkpoint_path = f\"/content/drive/MyDrive/AML_project/checkpoints/model_epoch_{epoch+1}.pth\"\n",
        "      torch.save(model.state_dict(), checkpoint_path)\n",
        "      print(f\"Modello salvato: {checkpoint_path}\")\n",
        "  \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import utils  # Replace with the actual module name\n",
        "\n",
        "importlib.reload(utils)"
      ],
      "metadata": {
        "id": "8DEAI7hiar0m",
        "outputId": "ba6c758a-7cf1-4634-f322-103b29e7f3a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'utils' from '/content/utils.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "import matplotlib.pyplot as plt\n",
        "from fvcore.nn import FlopCountAnalysis\n",
        "import random\n",
        "\n",
        "from utils import show\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "with torch.inference_mode():\n",
        "    random_index = random.randint(0, len(val_dataset_urban) - 1)\n",
        "    X, y = val_dataset_urban[random_index]\n",
        "    X = X.to(device).unsqueeze(dim=0)  # Aggiunge la dimensione batch\n",
        "    y = y.to(device)\n",
        "\n",
        "    start = timer()\n",
        "    output = model(X)\n",
        "    end = timer()\n",
        "\n",
        "    latency = end - start\n",
        "\n",
        "flops = FlopCountAnalysis(model, X.clone())\n",
        "\n",
        "\n",
        "normalized_masks = torch.nn.functional.softmax(output, dim=1)\n",
        "\n",
        "\n",
        "\n",
        "masks = [\n",
        "    normalized_masks[img_idx, sem_class_to_idx[cls]]\n",
        "    for img_idx in range(1)\n",
        "    for cls in SEM_CLASSES\n",
        "]\n",
        "\n",
        "show(masks)\n",
        "\n",
        "print(\"*********\")\n",
        "\n",
        "\n",
        "print(f\"FLOPs: {flops.total() / 1e9:.3f} GFLOPs\")\n",
        "print(f\"Average inference latency is {latency:.3f} seconds.\")\n",
        "\n",
        "# Converti output e ground truth per la visualizzazione\n",
        "out = output.squeeze().argmax(dim=0).cpu().numpy()  # Output segmentazione\n",
        "y_np = y.squeeze().cpu().numpy()  # Ground truth\n",
        "X_np = X.squeeze().cpu().permute(1, 2, 0).numpy()  # Immagine originale\n",
        "\n",
        "# Creazione della figura con tre immagini affiancate\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Immagine originale\n",
        "axes[0].imshow(X_np)\n",
        "axes[0].set_title(\"Original Image\")\n",
        "axes[0].axis(\"off\")\n",
        "\n",
        "# Predizione del modello\n",
        "axes[1].imshow(out, cmap=\"gray\")\n",
        "axes[1].set_title(\"Predicted Segmentation\")\n",
        "axes[1].axis(\"off\")\n",
        "\n",
        "# Ground truth\n",
        "axes[2].imshow(y_np, cmap=\"gray\")\n",
        "axes[2].set_title(\"Ground Truth\")\n",
        "axes[2].axis(\"off\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Conta i parametri del modello\n",
        "params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Params: {params / 1e6:.3f} M\")\n"
      ],
      "metadata": {
        "id": "bRByJkGflhLX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "fe25c73d-fa2d-40f0-dc0d-8ec6ea47df8b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*********\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 36 time(s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLOPs: 0.391 GFLOPs\n",
            "Average inference latency is 0.047 seconds.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 7 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Params: 43.016 M\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}